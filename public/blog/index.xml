<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Recent Posts on Nick Fisher's tech blog</title><link>https://www.nickolasfisher.com/blog/</link><description>Recent content in Recent Posts on Nick Fisher's tech blog</description><generator>Hugo</generator><language>en-US</language><copyright>2018-{year}</copyright><lastBuildDate>Sat, 01 May 2021 21:14:55 +0000</lastBuildDate><atom:link href="https://www.nickolasfisher.com/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>How to Prevent Certain Exceptions from Tripping a Resilience4j Circuit</title><link>https://www.nickolasfisher.com/blog/how-to-prevent-certain-exceptions-from-tripping-a-resilience4j-circuit/</link><pubDate>Sat, 01 May 2021 21:14:55 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-prevent-certain-exceptions-from-tripping-a-resilience4j-circuit/</guid><description>&lt;p>The source code for this article &lt;a href="https://github.com/nfisher23/java-failure-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>The Resilience4j circuit breaker by default considers any exception thrown inside of the &lt;strong>Supplier&lt;/strong> as a failure. If over 50% of the calls are failures and the rolling window max size is met, then it will prevent any future calls from going through.&lt;/p></description></item><item><title>Configuring, Testing, and Using Circuit Breakers on Rest API calls with Resilience4j</title><link>https://www.nickolasfisher.com/blog/configuring-testing-and-using-circuit-breakers-on-rest-api-calls-with-resilience4j/</link><pubDate>Sat, 01 May 2021 19:06:23 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/configuring-testing-and-using-circuit-breakers-on-rest-api-calls-with-resilience4j/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/java-failure-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>The circuit breaker pattern, popularized by Netflix [using Hystrix], exists for a couple of reasons, the most prominent being that it reduces load on a downstream service when it is not responding properly [presumably because it&amp;rsquo;s under duress]. By wrapping operations that might fail and get overloaded in a circuit breaker, we can prematurely prevent cascading failure and stop overloading those services.&lt;/p></description></item><item><title>How to Retry API Requests in Java using Resilience4j</title><link>https://www.nickolasfisher.com/blog/how-to-retry-api-requests-in-java-using-resilience4j/</link><pubDate>Sat, 01 May 2021 18:34:59 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-retry-api-requests-in-java-using-resilience4j/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/java-failure-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>When you&amp;rsquo;re working with distributed systems, it is often the case that some clones of a service running can be slow to respond, while still others are functioning perfectly normally. Therefore, when you just hit a load balancer and the load balancer chooses a backend, it can sometimes be beneficial to retry the request. Other things like periodic and small database stalls or random GC stop-the-worlds are examples where retries can smooth the experience for the client of your service.&lt;/p></description></item><item><title>How to Test Latency with a Mock Server in Java</title><link>https://www.nickolasfisher.com/blog/how-to-test-latency-with-a-mock-server-in-java/</link><pubDate>Sat, 01 May 2021 18:12:45 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-test-latency-with-a-mock-server-in-java/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/java-failure-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Very often, you will want to test service api clients using a &lt;a href="https://www.mock-server.com/">Mock Server&lt;/a> [for example, &lt;a href="https://nickolasfisher.com/blog/How-to-use-Mock-Server-to-End-to-End-Test-Any-WebClient-Calls-in-Spring-Boot-Webflux">testing the spring webclient with mockserver&lt;/a>]. And since network latency is a fact of life, not something we can merely ignore, actually injecting some latency to simulate timeouts will give us greater confidence that our system will behave as expected.&lt;/p></description></item><item><title>An Introduction to Redis Streams via Lettuce</title><link>https://www.nickolasfisher.com/blog/an-introduction-to-redis-streams-via-lettuce/</link><pubDate>Sat, 01 May 2021 15:22:58 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/an-introduction-to-redis-streams-via-lettuce/</guid><description>&lt;p>The source code for this article &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://redis.io/topics/streams-intro">Redis streams&lt;/a> are an interesting data structure that act as a sort of go-between for list and pub/sub operations: It&amp;rsquo;s like &lt;a href="https://nickolasfisher.com/blog/Working-with-Lists-in-Redis-using-Lettuce-and-Webflux">a list&lt;/a> in the sense that anything pushed onto the stream is retained, it&amp;rsquo;s like &lt;a href="https://nickolasfisher.com/blog/How-to-Publish-and-Subscribe-to-Redis-Using-Lettuce">pub/sub&lt;/a> in the sense that multiple consumers can see what is happening to it. There are many other features of streams that are covered in that article, but that&amp;rsquo;s at least how you can think of it at the start.&lt;/p></description></item><item><title>Using Redis as a Distributed Lock with Lettuce</title><link>https://www.nickolasfisher.com/blog/using-redis-as-a-distributed-lock-with-lettuce/</link><pubDate>Sat, 01 May 2021 14:44:31 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/using-redis-as-a-distributed-lock-with-lettuce/</guid><description>&lt;p>The source code for this article &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Using Redis as a best effort locking mechanism can be very useful in practice, to prevent two logical threads from clobbering each other. While redis locking is certainly not perfect, and &lt;a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">you shouldn&amp;rsquo;t use redis locking if the underlying operation can&amp;rsquo;t be occasionally done twice&lt;/a>, it can still be useful for that &amp;ldquo;best effort, do this once&amp;rdquo; use case.&lt;/p></description></item><item><title>Subscribing to Channels in Clustered Redis With Lettuce</title><link>https://www.nickolasfisher.com/blog/subscribing-to-channels-in-clustered-redis-with-lettuce/</link><pubDate>Sun, 25 Apr 2021 18:43:42 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/subscribing-to-channels-in-clustered-redis-with-lettuce/</guid><description>&lt;p>We already know &lt;a href="https://nickolasfisher.com/blog/Subscribing-to-Redis-Channels-with-Java-Spring-Boot-and-Lettuce">how to subscribe to redis using lettuce&lt;/a> when it&amp;rsquo;s not running in clustered mode. If it&amp;rsquo;s running in clustered mode, it&amp;rsquo;s not terribly different, but I did discover one thing that is interesting, which is the subject of this article.&lt;/p></description></item><item><title>Pre Loading Lua Scripts into Clustered Redis with Lettuce</title><link>https://www.nickolasfisher.com/blog/pre-loading-lua-scripts-into-clustered-redis-with-lettuce/</link><pubDate>Sun, 25 Apr 2021 17:37:07 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/pre-loading-lua-scripts-into-clustered-redis-with-lettuce/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on github&lt;/a>.&lt;/p>
&lt;p>In a previous article, we showed how to &lt;a href="https://nickolasfisher.com/blog/Pre-Loading-a-Lua-Script-into-Redis-With-Lettuce">efficiently execute a lua script in redis using lettuce&lt;/a>. To really scale our caching solution horizontally [and elegantly deal with many scaling headaches], we will also want to make sure we can execute our lua scripts against clustered redis, which as we&amp;rsquo;ll see here is pretty straightforward.&lt;/p></description></item><item><title>Why Redis Pub/Sub is not SQS, and Vice Versa</title><link>https://www.nickolasfisher.com/blog/why-redis-pubsub-is-not-sqs-and-vice-versa/</link><pubDate>Sat, 24 Apr 2021 23:52:19 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/why-redis-pubsub-is-not-sqs-and-vice-versa/</guid><description>&lt;p>&lt;a href="https://redis.io/topics/pubsub">Redis has a pub/sub feature&lt;/a> whereby there are publishers and subscribers, and publishers can fanout messages to subscribers. SQS [ &lt;a href="https://aws.amazon.com/sqs/">amazon&amp;rsquo;s simple queue service&lt;/a>] has message senders and receivers. They can both be useful, but in practice they produce different results.&lt;/p></description></item><item><title>Optimistic Locking in Redis with Reactive Lettuce</title><link>https://www.nickolasfisher.com/blog/optimistic-locking-in-redis-with-reactive-lettuce/</link><pubDate>Sat, 24 Apr 2021 21:32:36 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/optimistic-locking-in-redis-with-reactive-lettuce/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Optimistic Locking in Redis is one of the only reasons to want to use transactions, in my opinion. You can ensure a grouping of atomic operations only occur if a watched key does not change out from underneath you. On the CLI, this might start with:&lt;/p></description></item><item><title>Redis Transactions, Reactive Lettuce: Buyer Beware</title><link>https://www.nickolasfisher.com/blog/redis-transactions-reactive-lettuce-buyer-beware/</link><pubDate>Sat, 24 Apr 2021 20:48:04 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/redis-transactions-reactive-lettuce-buyer-beware/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Redis Transactions do not operate exactly the way you would expect if you&amp;rsquo;re coming from a relational database management system like MySQL or postrgres. It&amp;rsquo;s mostly useful for optimistic locking, but honestly there are better ways to accomplish many of the things you&amp;rsquo;re probably trying to, like &lt;a href="https://nickolasfisher.com/blog/How-to-Run-a-Lua-Script-against-Redis-using-Lettuce">running a lua script with arguments&lt;/a> [which is guaranteed to be atomic]. The &lt;a href="https://redis.io/topics/transactions">documentation on transactions in redis&lt;/a> describes some of the caveats, the biggest one probably being that it does not support rollbacks, only commits or discards.&lt;/p></description></item><item><title>How to Prevent DEBUG Logging by Test Containers when Running Unit Tests in Java</title><link>https://www.nickolasfisher.com/blog/how-to-prevent-debug-logging-by-test-containers-when-running-unit-tests-in-java/</link><pubDate>Sat, 24 Apr 2021 20:35:47 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-prevent-debug-logging-by-test-containers-when-running-unit-tests-in-java/</guid><description>&lt;p>I have been playing around with test containers lately [ &lt;a href="https://nickolasfisher.com/blog/How-to-use-a-Redis-Test-Container-with-LettuceSpring-Boot-Webflux">redis test containers for testing lettuce&lt;/a> and &lt;a href="https://nickolasfisher.com/blog/Setup-and-Use-a-DynamoDB-Test-Container-with-the-AWS-Java-SDK-20">dynamodb test containers for testing the AWS SDK 2.0&lt;/a>, to be specific], and I found soon after using them that I was getting by default a stream of DEBUG level logs whenever I ran my test suite. This was annoying, so I went digging for a solution.&lt;/p></description></item><item><title>Subscribing to Redis Channels with Java, Spring Boot, and Lettuce</title><link>https://www.nickolasfisher.com/blog/subscribing-to-redis-channels-with-java-spring-boot-and-lettuce/</link><pubDate>Sat, 24 Apr 2021 20:05:52 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/subscribing-to-redis-channels-with-java-spring-boot-and-lettuce/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Pub/Sub in redis allows a publisher to send things to subscribers without knowing who is actually subscribed. In a previous post, we covered &lt;a href="https://nickolasfisher.com/blog/How-to-Publish-and-Subscribe-to-Redis-Using-Lettuce">a simple unit test for publishing and subscribing to lettuce&lt;/a>, but if you want to have a subscription initialized on application startup, and respond to events, we&amp;rsquo;ll have to do a bit more, which I&amp;rsquo;ll demonstrate here.&lt;/p></description></item><item><title>Pre Loading a Lua Script into Redis With Lettuce</title><link>https://www.nickolasfisher.com/blog/pre-loading-a-lua-script-into-redis-with-lettuce/</link><pubDate>Sat, 24 Apr 2021 18:05:29 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/pre-loading-a-lua-script-into-redis-with-lettuce/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>In my last article on &lt;a href="https://nickolasfisher.com/blog/How-to-Run-a-Lua-Script-against-Redis-using-Lettuce">running a lua script against redis with lettuce&lt;/a>, we just sent the entire script [that redis will execute atomically] along with the arguments every time. For very small scripts this is unlikely to be a problem, but there is definitely a more efficient way to do this, using &lt;a href="https://redis.io/commands/evalsha">EVALSHA&lt;/a>.&lt;/p></description></item><item><title>How to Run a Lua Script against Redis using Lettuce</title><link>https://www.nickolasfisher.com/blog/how-to-run-a-lua-script-against-redis-using-lettuce/</link><pubDate>Sat, 24 Apr 2021 16:55:51 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-run-a-lua-script-against-redis-using-lettuce/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Running a lua script against redis is done using &lt;a href="https://redis.io/commands/eval">EVAL&lt;/a>. The primary benefit of using a lua script is that the entire script is guaranteed to be run at once, and nothing else will interfere with it [it&amp;rsquo;s atomic]. This allows for operating on multiple keys, or check-then-set type operations on the same key.&lt;/p></description></item><item><title>How to Publish and Subscribe to Redis Using Lettuce</title><link>https://www.nickolasfisher.com/blog/how-to-publish-and-subscribe-to-redis-using-lettuce/</link><pubDate>Sat, 24 Apr 2021 16:37:18 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-publish-and-subscribe-to-redis-using-lettuce/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Subscribing to topics in redis allows for a &lt;em>fanout&lt;/em> behavior, where any number of subscribers can be notified of a message from a publisher.&lt;/p></description></item><item><title>Expiring Individual Elements in a Redis Set</title><link>https://www.nickolasfisher.com/blog/expiring-individual-elements-in-a-redis-set/</link><pubDate>Sun, 18 Apr 2021 20:13:11 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/expiring-individual-elements-in-a-redis-set/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Redis does not allow you to set the expiration on individual members in a set, it only allows you to set an expiration on the entire set itself. If you want to have a sort of expiry on individual elements in a set, this article shares a workaround to that problem that works well in practice. Because I have already written a lot of &lt;a href="https://nickolasfisher.com/blog/How-to-use-Embedded-Redis-to-Test-a-Lettuce-Client-in-Spring-Boot-Webflux">boilerplate code for testing any redis operation using lettuce&lt;/a>, I&amp;rsquo;m going to be showing you this technique using a reactive lettuce client, however the basic concept should transfer easily to any other client.&lt;/p></description></item><item><title>Lettuce, MSETNX, and Clustered Redis</title><link>https://www.nickolasfisher.com/blog/lettuce-msetnx-and-clustered-redis/</link><pubDate>Sat, 17 Apr 2021 09:35:41 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/lettuce-msetnx-and-clustered-redis/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://redis.io/commands/msetnx">MSETNX&lt;/a> when you&amp;rsquo;re working with a single redis primary node is simple enough to understand: it sets all of the key/value pairs, or none at all. If one of the keys already exists in the cluster, then all of them are rejected.&lt;/p></description></item><item><title>A Guide to Operating on Sorted Sets in Redis with Lettuce</title><link>https://www.nickolasfisher.com/blog/a-guide-to-operating-on-sorted-sets-in-redis-with-lettuce/</link><pubDate>Sat, 17 Apr 2021 08:15:31 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-guide-to-operating-on-sorted-sets-in-redis-with-lettuce/</guid><description>&lt;p>Sorted Sets in redis are one of my personal favorite tools when operating at scale. As of this writing, &lt;a href="https://redis.io/commands/#sorted_set">there are over 30 unique operations you can perform against sorted sets in redis&lt;/a>. This article will focus on some of the more common ones you&amp;rsquo;re going to need to know, and it will use a reactive lettuce client to demonstrate them.&lt;/p></description></item><item><title>A Guide to Operating on Multiple Sets in Redis with Lettuce</title><link>https://www.nickolasfisher.com/blog/a-guide-to-operating-on-multiple-sets-in-redis-with-lettuce/</link><pubDate>Sat, 17 Apr 2021 08:12:31 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-guide-to-operating-on-multiple-sets-in-redis-with-lettuce/</guid><description>&lt;p>In the last article, we showed how to do some of the most common single set operations against redis, this article will focus on operating on multiple sets using a lettuce client against redis. Specifically, we&amp;rsquo;ll focus on subtracting, intersecting, and adding sets. The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p></description></item><item><title>A Guide to Simple Set Operations in Redis with Lettuce</title><link>https://www.nickolasfisher.com/blog/a-guide-to-simple-set-operations-in-redis-with-lettuce/</link><pubDate>Sat, 17 Apr 2021 08:09:37 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-guide-to-simple-set-operations-in-redis-with-lettuce/</guid><description>&lt;p>There are, as of this writing, about &lt;a href="https://redis.io/commands/#set">15 distinct operations available to someone wanting to work with sets in redis&lt;/a>. This article seeks to cover some of the more basic ones using a reactive lettuce client, and &lt;a href="https://nickolasfisher.com/blog/A-Guide-to-Operating-on-Multiple-Sets-in-Redis-with-Lettuce">a follow up article&lt;/a> will seek to deal with explaining some of the more common operations against multiple sets, rather than a single set in this case.&lt;/p></description></item><item><title>Working with Redis Hashes using Lettuce And Webflux</title><link>https://www.nickolasfisher.com/blog/working-with-redis-hashes-using-lettuce-and-webflux/</link><pubDate>Sun, 11 Apr 2021 22:26:29 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/working-with-redis-hashes-using-lettuce-and-webflux/</guid><description>&lt;p>There are about &lt;a href="https://redis.io/commands/#hash">15 or so commands you can execute against redis for hash types&lt;/a> as of this writing. This article will demonstrate some of the more common operations you&amp;rsquo;re likely to need when using lettuce as your client.&lt;/p></description></item><item><title>Working with Lists in Redis using Lettuce and Webflux</title><link>https://www.nickolasfisher.com/blog/working-with-lists-in-redis-using-lettuce-and-webflux/</link><pubDate>Sun, 11 Apr 2021 21:14:08 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/working-with-lists-in-redis-using-lettuce-and-webflux/</guid><description>&lt;p>As of this writing, there are a solid &lt;a href="https://redis.io/commands/#list">twenty or so commands you can execute against redis for the list data type&lt;/a>. This article will be walking through some of the more common operations you are likely to need when interacting with redis and lists using lettuce, and &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">the source code can be found on Github&lt;/a>.&lt;/p></description></item><item><title>Working with String Types in Redis using Lettuce and Webflux</title><link>https://www.nickolasfisher.com/blog/working-with-string-types-in-redis-using-lettuce-and-webflux/</link><pubDate>Sun, 11 Apr 2021 19:01:16 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/working-with-string-types-in-redis-using-lettuce-and-webflux/</guid><description>&lt;p>The source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>There are, as of this writing, &lt;a href="https://redis.io/commands/#string">27 different string operations available in the redis API&lt;/a>. Lettuce appears to have interfaces that directly support all of them.&lt;/p></description></item><item><title>Using Hashtags in Clustered Redis with Lettuce and Webflux</title><link>https://www.nickolasfisher.com/blog/using-hashtags-in-clustered-redis-with-lettuce-and-webflux/</link><pubDate>Sun, 11 Apr 2021 16:12:09 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/using-hashtags-in-clustered-redis-with-lettuce-and-webflux/</guid><description>&lt;p>In clustered redis, any non hash tagged key can be sent unpredictably [well, actually predictably, if you know the formula] to any given primary node in the cluster. The very basic way it works is:&lt;/p></description></item><item><title>Breaking down Lettuce MSET Commands in Clustered Redis</title><link>https://www.nickolasfisher.com/blog/breaking-down-lettuce-mset-commands-in-clustered-redis/</link><pubDate>Sat, 10 Apr 2021 23:26:07 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/breaking-down-lettuce-mset-commands-in-clustered-redis/</guid><description>&lt;p>To follow along with this post, it would be best if you have already &lt;a href="https://nickolasfisher.com/blog/Bootstrap-a-Local-Sharded-Redis-Cluster-in-Five-Minutes">set up your local redis cluster&lt;/a> and know how to &lt;a href="https://nickolasfisher.com/blog/Configuring-Lettuce-to-work-with-Clustered-Redis">connect to a redis cluster and interact with it via Lettuce&lt;/a>. And the source code for what follows &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p></description></item><item><title>Configuring Lettuce/Webflux to work with Clustered Redis</title><link>https://www.nickolasfisher.com/blog/configuring-lettucewebflux-to-work-with-clustered-redis/</link><pubDate>Sat, 10 Apr 2021 22:27:54 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/configuring-lettucewebflux-to-work-with-clustered-redis/</guid><description>&lt;p>Lettuce has some pretty nice out of the box support for working with clustered redis. This combination&amp;ndash;a reactive client and application along with clustered redis&amp;ndash;is about as scalable, performant, and resilient as things can get in distributed systems [though there are other tradeoffs which are not the subject of this post].&lt;/p></description></item><item><title>Bootstrap a Local Sharded Redis Cluster in Five Minutes</title><link>https://www.nickolasfisher.com/blog/bootstrap-a-local-sharded-redis-cluster-in-five-minutes/</link><pubDate>Sat, 10 Apr 2021 18:24:12 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/bootstrap-a-local-sharded-redis-cluster-in-five-minutes/</guid><description>&lt;p>If you&amp;rsquo;re interested in understanding details of how clustered redis works [that is to say, if you&amp;rsquo;re more or less responsible for operationalizing it], there is an excellent &lt;a href="https://redis.io/topics/cluster-tutorial">section in the redis documentation&lt;/a> that goes into some detail on it. I would advise everyone to read that at some point, but if you just want to get started hacking this is the TLDR; article that you&amp;rsquo;re looking for. We will run through some basic commands to get up and running, and you can use this cluster to help figure out the details later on.&lt;/p></description></item><item><title>Setup and Use a DynamoDB Test Container with the AWS Java SDK 2.0</title><link>https://www.nickolasfisher.com/blog/setup-and-use-a-dynamodb-test-container-with-the-aws-java-sdk-20/</link><pubDate>Sat, 10 Apr 2021 16:13:09 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/setup-and-use-a-dynamodb-test-container-with-the-aws-java-sdk-20/</guid><description>&lt;p>The source code for this article &lt;a href="https://github.com/nfisher23/webflux-and-dynamo">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Using &lt;a href="https://nickolasfisher.com/blog/Configuring-an-In-Memory-DynamoDB-instance-with-Java-for-Integration-Testing">embedded dynamodb for testing&lt;/a> is, in my experience, kind of flakey and unpredictable. Because of the weird way it pulls in SQLite on a per operating system basis, it can sometimes work locally and not work on the build server. Sometimes it&amp;rsquo;s just not working for some unexplained reason and wiping the directory that the code is in and re-cloning fixes it. Not a fun time.&lt;/p></description></item><item><title>How to Configure Lettuce to use Redis Read Replicas in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-configure-lettuce-to-use-redis-read-replicas-in-spring-boot-webflux/</link><pubDate>Sun, 28 Mar 2021 19:22:27 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-configure-lettuce-to-use-redis-read-replicas-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Lettuce supports reading from redis replicas, but with the caveat that it doesn&amp;rsquo;t [out of the box] provide you with the fine-grained control over &lt;em>when&lt;/em> to read from the replicas that you&amp;rsquo;re likely to want.&lt;/p></description></item><item><title>Set up a Basic Leader/Follower Redis Cluster Locally using Docker</title><link>https://www.nickolasfisher.com/blog/set-up-a-basic-leaderfollower-redis-cluster-locally-using-docker/</link><pubDate>Sun, 28 Mar 2021 18:57:07 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/set-up-a-basic-leaderfollower-redis-cluster-locally-using-docker/</guid><description>&lt;p>In general, you will want to keep your development environment and your higher environments as similar as makes sense [times it doesn&amp;rsquo;t make sense: when it costs too much], to catch bugs early and often. Here, we&amp;rsquo;ll quickly run through how to set up a leader/follower topology for redis using docker/docker-compose on your local machine.&lt;/p></description></item><item><title>How to Configure Lettuce to connect to a local Redis Instance with Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-configure-lettuce-to-connect-to-a-local-redis-instance-with-webflux/</link><pubDate>Sun, 28 Mar 2021 17:49:16 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-configure-lettuce-to-connect-to-a-local-redis-instance-with-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/reactive-redis">can be found on Github&lt;/a>.&lt;/p>
&lt;p>In a previous post, we detailed &lt;a href="https://nickolasfisher.com/blog/How-to-use-a-Redis-Test-Container-with-LettuceSpring-Boot-Webflux">how to write integration tests for lettuce clients in spring boot webflux&lt;/a> using a redis test container. That&amp;rsquo;s fine and well when you&amp;rsquo;re just writing code for a quick feedback loop, but is useless when it comes to running the application in real life. This post will start up redis locally and then explain how to best connect to it using lettuce in webflux.&lt;/p></description></item><item><title>Atomic Incrementing in DynamoDB with the Java AWS SDK 2.0</title><link>https://www.nickolasfisher.com/blog/atomic-incrementing-in-dynamodb-with-the-java-aws-sdk-20/</link><pubDate>Sun, 28 Mar 2021 02:00:30 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/atomic-incrementing-in-dynamodb-with-the-java-aws-sdk-20/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/webflux-and-dynamo">can be found on Github&lt;/a>.&lt;/p>
&lt;p>When you update an item in DynamoDB, you can optionally update the item in place. That is, instead of &lt;strong>read-increment-write&lt;/strong>, you can just issue a command that says &lt;strong>increment this value in place&lt;/strong>. This behavior is detailed in the &lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.AtomicCounters">AWS documentation&lt;/a>, and I will provide an example for how to do so with the Java AWS SDK 2.0, which has full reactive support.&lt;/p></description></item><item><title>How to use a Redis Test Container with Lettuce/Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-use-a-redis-test-container-with-lettucespring-boot-webflux/</link><pubDate>Sat, 27 Mar 2021 23:52:07 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-a-redis-test-container-with-lettucespring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/reactive-redis">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Another way to write integration tests for code that verifies your interactions with redis actually make sense is to use a &lt;a href="https://www.testcontainers.org/">test container&lt;/a>. This framework assumes you have docker up and running, but if you do it will pull a specified container image [typically you&amp;rsquo;ll just use docker hub, though it&amp;rsquo;s important to note that they rate limit you, so don&amp;rsquo;t go overboard], then you can interact with that container in your integration tests.&lt;/p></description></item><item><title>How to use Embedded Redis to Test a Lettuce Client in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-use-embedded-redis-to-test-a-lettuce-client-in-spring-boot-webflux/</link><pubDate>Sat, 27 Mar 2021 21:22:32 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-embedded-redis-to-test-a-lettuce-client-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this article &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/reactive-redis">can be found on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://github.com/lettuce-io/lettuce-core">Lettuce&lt;/a> is a redis client with reactive support. There is a super handy &lt;a href="https://github.com/kstyrc/embedded-redis">embedded redis for java project&lt;/a> out there, and this kind of integration testing inside your service is worth its weight in gold, in my humble opinion. This post will detail how to merge both of these worlds together, and set up redis integration tests when you&amp;rsquo;re using a lettuce client.&lt;/p></description></item><item><title>Making Sense of Mono Error Handling in Spring Boot Webflux/Project Reactor</title><link>https://www.nickolasfisher.com/blog/making-sense-of-mono-error-handling-in-spring-boot-webfluxproject-reactor/</link><pubDate>Sun, 21 Mar 2021 18:27:16 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/making-sense-of-mono-error-handling-in-spring-boot-webfluxproject-reactor/</guid><description>&lt;p>A Reactor &lt;a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html">Mono&lt;/a> comes with a lot of methods that allow you to do things when errors occur:&lt;/p></description></item><item><title>How to Zip Reactor Mono Objects that Return Void</title><link>https://www.nickolasfisher.com/blog/how-to-zip-reactor-mono-objects-that-return-void/</link><pubDate>Sat, 20 Mar 2021 19:14:57 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-zip-reactor-mono-objects-that-return-void/</guid><description>&lt;p>Leveraging &lt;a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html#zip-java.lang.Iterable-java.util.function.Function-">Mono.zip&lt;/a> appropriately will [with the right configuration] lead to a high amount of performance and concurrency. There is one caveat to its usage though:&lt;/p></description></item><item><title>How to Unit Test that a Reactor Mono was Actually Subscribed to</title><link>https://www.nickolasfisher.com/blog/how-to-unit-test-that-a-reactor-mono-was-actually-subscribed-to/</link><pubDate>Sat, 13 Mar 2021 22:35:48 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-unit-test-that-a-reactor-mono-was-actually-subscribed-to/</guid><description>&lt;p>There&amp;rsquo;s a very insidious bug that can happen when you&amp;rsquo;re writing reactive code, and it basically comes down to whether an underlying &lt;strong>Mono&lt;/strong> in a chain of operations was actually &lt;strong>subscribed to&lt;/strong>, rather than merely observing a method invocation. I&amp;rsquo;ll demonstrate with an example.&lt;/p></description></item><item><title>How to use Caffeine Caches Effectively in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-use-caffeine-caches-effectively-in-spring-boot-webflux/</link><pubDate>Sat, 13 Mar 2021 21:36:45 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-caffeine-caches-effectively-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/api-calls-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>When someone talks about a caffeine cache, they are talking about &lt;a href="https://github.com/ben-manes/caffeine">Ben Manes caching library&lt;/a>, which is a high performance, in memory cache written for java. If you&amp;rsquo;re using reactive streams, you can&amp;rsquo;t reliably use a LoadingCache because it&amp;rsquo;s blocking by default. Thankfully, tapping into a couple of basic features of reactive streams and caffeine can get us there.&lt;/p></description></item><item><title>Setting up a Python Lambda to Trigger on DynamoDB Streams via the AWS CLI</title><link>https://www.nickolasfisher.com/blog/setting-up-a-python-lambda-to-trigger-on-dynamodb-streams-via-the-aws-cli/</link><pubDate>Sun, 07 Feb 2021 19:47:50 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/setting-up-a-python-lambda-to-trigger-on-dynamodb-streams-via-the-aws-cli/</guid><description>&lt;p>DynamoDB streams record information about what has changed in a DynamoDB table, and AWS lambdas are ways to run code without managing servers yourself. DynamoDB streams also have an integration with AWS Lambdas so that any change to a DynamoDB table can be processed by an AWS Lambda&amp;ndash;still without worrying about keeping your servers up or maintaining them. That is the subject of this post.&lt;/p></description></item><item><title>Basic Python Lambda Function Uploads using the AWS CLI</title><link>https://www.nickolasfisher.com/blog/basic-python-lambda-function-uploads-using-the-aws-cli/</link><pubDate>Sat, 06 Feb 2021 21:07:12 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/basic-python-lambda-function-uploads-using-the-aws-cli/</guid><description>&lt;p>AWS Lambda functions were the first &amp;ldquo;serverless&amp;rdquo; way to run code. Of course, there are still servers, but the point is that you can nearly forget about managing those servers and all of that is owned by AWS.&lt;/p></description></item><item><title>DynamoDB Transactions and Java</title><link>https://www.nickolasfisher.com/blog/dynamodb-transactions-and-java/</link><pubDate>Sat, 28 Nov 2020 20:57:47 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/dynamodb-transactions-and-java/</guid><description>&lt;p>DynamoDB transactions can be used for &lt;em>atomic&lt;/em> updates. Atomic updates in DynamoDB without transactions can be difficult to implement&amp;ndash;you&amp;rsquo;ll often have to manage the current state of the update yourself in something like a saga, and have business logic specific rollback procedures. Further, without a transaction manager, the data will be in an inconsistent state at some point in time while the saga is ongoing. An alternative to that is a Two Phase Commit, but that&amp;rsquo;s also expensive both from the standpoint of developers making it work as well as performance [2PC typically call for a lock being held during the operation, and even then there&amp;rsquo;s a possibility that the operation ends up in an inconsistent state at some point].&lt;/p></description></item><item><title>Publishing to SNS in Java with the AWS SDK 2.0</title><link>https://www.nickolasfisher.com/blog/publishing-to-sns-in-java-with-the-aws-sdk-20/</link><pubDate>Sat, 28 Nov 2020 20:16:05 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/publishing-to-sns-in-java-with-the-aws-sdk-20/</guid><description>&lt;p>SNS is a medium to broadcast messages to multiple subscribers. A common use case is to have multiple SQS queues subscribing to the same SNS topic&amp;ndash;this way, the &lt;em>publishing&lt;/em> application only needs to focus on events that are specific to its business use case, and &lt;em>subscribing&lt;/em> applications can configure an SQS queue and consume the event independently of other services. This helps organizations scale and significantly reduces the need to communicate between teams&amp;ndash;each team can focus on its contract and business use case.&lt;/p></description></item><item><title>Working with Nested Attributes, DynamoDB, and the Java SDK 2.0</title><link>https://www.nickolasfisher.com/blog/working-with-nested-attributes-dynamodb-and-the-java-sdk-20/</link><pubDate>Sun, 15 Nov 2020 22:59:11 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/working-with-nested-attributes-dynamodb-and-the-java-sdk-20/</guid><description>&lt;p>&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.Attributes.html">Nested attributes in DynamoDB&lt;/a> are a way to group data within an item together. The attributes are said to be nested if they are embedded within another attribute.&lt;/p></description></item><item><title>Scanning a DynamoDB table in Java with the AWS SDK 2.0</title><link>https://www.nickolasfisher.com/blog/scanning-a-dynamodb-table-in-java-with-the-aws-sdk-20/</link><pubDate>Sat, 07 Nov 2020 02:08:37 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/scanning-a-dynamodb-table-in-java-with-the-aws-sdk-20/</guid><description>&lt;p>&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html">Scanning in DynamoDB&lt;/a> is exactly what it sounds like: loop through every single record in a table, optionally filtering for items with a certain condition when dynamo returns them to you. In general, you &lt;em>shouldn&amp;rsquo;t do this&lt;/em>. DynamoDB is designed to store and manage a very large amount of data. Scanning through a large amount of data is very expensive, even in a distributed world. In the best case, you&amp;rsquo;ll be waiting a long time to see results. In the worst case, you might see service outages as you burn through your RCUs.&lt;/p></description></item><item><title>DynamoDB and Duplicate Keys in Global Secondary Indexes</title><link>https://www.nickolasfisher.com/blog/dynamodb-and-duplicate-keys-in-global-secondary-indexes/</link><pubDate>Sun, 01 Nov 2020 23:27:39 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/dynamodb-and-duplicate-keys-in-global-secondary-indexes/</guid><description>&lt;p>If there&amp;rsquo;s something in the documentation about what the behavior of a DynamoDB Global Secondary Index is when there are duplicate keys in the index, it isn&amp;rsquo;t easy to find. I tested this empirically with an embedded DynamoDB mock for java and will quickly share my findings here with you.&lt;/p></description></item><item><title>Query a DynamoDB Global Secondary Index in Java</title><link>https://www.nickolasfisher.com/blog/query-a-dynamodb-global-secondary-index-in-java/</link><pubDate>Sun, 01 Nov 2020 22:40:46 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/query-a-dynamodb-global-secondary-index-in-java/</guid><description>&lt;p>A &lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html">DynamoDB Global Secondary Index&lt;/a> is an eventually consistent way to efficiently query for data that is not normally found without a table scan. It has &lt;a href="https://nickolasfisher.com/blog/Query-a-DynamoDB-Local-Secondary-Index-with-Java">some similarities to Local Secondary Indexes, which we covered in the last post&lt;/a>, but are more flexible than them because they can be created, updated, and deleted after the base table has been created, which is not true of Local Secondary Indexes.&lt;/p></description></item><item><title>Query a DynamoDB Local Secondary Index with Java</title><link>https://www.nickolasfisher.com/blog/query-a-dynamodb-local-secondary-index-with-java/</link><pubDate>Sat, 31 Oct 2020 22:49:54 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/query-a-dynamodb-local-secondary-index-with-java/</guid><description>&lt;p>DynamoDB&amp;rsquo;s Local Secondary Indexes allow for more query flexibility than a traditional partition and range key combination. They are also the only index in DynamoDB where a strongly consistent read can be requested [global secondary indexes, the other index that dynamo supports, can at best be eventually consistent]. I will walk through an example for how to use local secondary indexes in dynamo using the AWS SDK 2.0 for Java, which has full reactive support, in this post.&lt;/p></description></item><item><title>Set Time to Live [TTL] on DynamoDB Items using Java</title><link>https://www.nickolasfisher.com/blog/set-time-to-live-ttl-on-dynamodb-items-using-java/</link><pubDate>Sun, 18 Oct 2020 13:43:39 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/set-time-to-live-ttl-on-dynamodb-items-using-java/</guid><description>&lt;p>In this post, we&amp;rsquo;ll demonstrate how &lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html">expiring items in DynamoDB&lt;/a> works in java, using the AWS SDK 2.0+, which has full reactive support.&lt;/p></description></item><item><title>Querying DynamoDB in Java with the AWS SDK 2.0</title><link>https://www.nickolasfisher.com/blog/querying-dynamodb-in-java-with-the-aws-sdk-20/</link><pubDate>Sun, 18 Oct 2020 13:38:22 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/querying-dynamodb-in-java-with-the-aws-sdk-20/</guid><description>&lt;p>Queries in DynamoDB allow you to find data. This is only an option to you if your table has a partition and sort key.&lt;/p></description></item><item><title>Optimistic Locking in Java and DynamoDB</title><link>https://www.nickolasfisher.com/blog/optimistic-locking-in-java-and-dynamodb/</link><pubDate>Sun, 11 Oct 2020 20:19:42 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/optimistic-locking-in-java-and-dynamodb/</guid><description>&lt;p>I&amp;rsquo;ve previously written about using &lt;a href="https://nickolasfisher.com/blog/How-to-use-Optimistic-Locking-in-DynamoDB-via-the-AWS-CLI">conditional expressions to achieve optimistic locking in DynamoDB&lt;/a>, that example used the command line. I will now demonstrate how to do the same thing in java code, leveraging the AWS SDK 2.0 [with full reactive support].&lt;/p></description></item><item><title>Configuring an In Memory DynamoDB instance with Java for Integration Testing</title><link>https://www.nickolasfisher.com/blog/configuring-an-in-memory-dynamodb-instance-with-java-for-integration-testing/</link><pubDate>Sat, 10 Oct 2020 00:02:25 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/configuring-an-in-memory-dynamodb-instance-with-java-for-integration-testing/</guid><description>&lt;p>While using the AWS SDK 2.0, which has support for reactive programming, it became clear that there was no straightforward support for an embedded dynamo db instance for testing. I spent a fair amount of time figuring it out by starting with &lt;a href="https://github.com/aws/aws-sdk-java-v2/blob/93269d4c0416d0f72e086774265847d6af0d54ec/services-custom/dynamodb-enhanced/src/test/java/software/amazon/awssdk/extensions/dynamodb/mappingclient/functionaltests/LocalDynamoDb.java">this github link&lt;/a> and ultimately adapting it to my own needs.&lt;/p></description></item><item><title>In-Memory Caching in Sprint Boot Webflux/Project Reactor</title><link>https://www.nickolasfisher.com/blog/inmemory-caching-in-sprint-boot-webfluxproject-reactor/</link><pubDate>Sat, 03 Oct 2020 22:41:59 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/inmemory-caching-in-sprint-boot-webfluxproject-reactor/</guid><description>&lt;p>Sample code for this article &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/api-calls-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>In memory caching can significantly improve performance in a microservices environment, usually because of the tail latency involved in calling downstream services. Caching can also &lt;em>help&lt;/em> with resilience, though the extent to which that matters will depend on how you&amp;rsquo;re actually leveraging that caching. There are two flavors of caching that you&amp;rsquo;re like to want to use, the first is using the Mono as a hot source [which is demonstrated here], and the second would be when you want to &lt;a href="https://nickolasfisher.com/blog/How-to-use-Caffeine-Caches-Effectively-in-Spring-Boot-Webflux">selectively cache individual key/value pairs&lt;/a>.&lt;/p></description></item><item><title>How to Automatically Retry on a Webclient Timeout in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-automatically-retry-on-a-webclient-timeout-in-spring-boot-webflux/</link><pubDate>Sat, 03 Oct 2020 16:09:51 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-automatically-retry-on-a-webclient-timeout-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/api-calls-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Intermittent network flapping, or any one downstream host of several clones responding slowly, is a not uncommon thing that happens in a microservices architecture, especially if you&amp;rsquo;re using java applications, where the JIT compiler can often make initial requests slower than they ought to be.&lt;/p></description></item><item><title>How to Have a Fallback on Errors Calling Downstream Services in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-have-a-fallback-on-errors-calling-downstream-services-in-spring-boot-webflux/</link><pubDate>Sat, 26 Sep 2020 16:04:14 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-have-a-fallback-on-errors-calling-downstream-services-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post is &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/api-calls-and-resilience">available on Github&lt;/a>.&lt;/p>
&lt;p>Things break. When you start adding more and more microservices, things will break a lot more. This post is about how to provide a degraded experience to your users when things break.&lt;/p></description></item><item><title>How to Make Parallel API calls in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-make-parallel-api-calls-in-spring-boot-webflux/</link><pubDate>Sat, 19 Sep 2020 16:03:01 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-make-parallel-api-calls-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/api-calls-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Following up on the last post, which was making sequential calls to downstream services, sometimes you are in a position where you can make calls in parallel and merge the results. In this case, we want to use &lt;strong>zip&lt;/strong>.&lt;/p></description></item><item><title>How to Make Sequential API Calls and Merge the Results In Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-make-sequential-api-calls-and-merge-the-results-in-spring-boot-webflux/</link><pubDate>Sat, 19 Sep 2020 16:01:14 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-make-sequential-api-calls-and-merge-the-results-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this article &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/api-calls-and-resilience">can be found on Github&lt;/a>.&lt;/p>
&lt;p>In reactive programming, it&amp;rsquo;s a game of callbacks. In the vast majority of cases, you will want to defer all of your I/O operations to the library you are using [typically, netty, under the hood], and stay focused on setting up the flow so that the right functions are invoked in the right order. Sometimes you will want to make calls in parallel, sometimes you need data from a previous call or operation available in order to invoke that right function.&lt;/p></description></item><item><title>How to Setup a Reactive SQS Listener Using the AWS SDK and Spring Boot</title><link>https://www.nickolasfisher.com/blog/how-to-setup-a-reactive-sqs-listener-using-the-aws-sdk-and-spring-boot/</link><pubDate>Sat, 12 Sep 2020 21:42:52 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-setup-a-reactive-sqs-listener-using-the-aws-sdk-and-spring-boot/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/reactive-sqs">can be found on Github&lt;/a>.&lt;/p>
&lt;p>Following up on the previous post where we showed &lt;a href="https://nickolasfisher.com/blog/How-to-Send-SQS-Messages-to-Localstack-with-the-AWS-Java-SDK-20">how to send SQS messages to Localstack using the AWS SDK for Java 2.0&lt;/a>, we will now demonstrate how to write code that continuously polls for SQS messages, processes them, then deletes them off the queue.&lt;/p></description></item><item><title>How to Send SQS Messages to Localstack with the AWS Java SDK 2.0</title><link>https://www.nickolasfisher.com/blog/how-to-send-sqs-messages-to-localstack-with-the-aws-java-sdk-20/</link><pubDate>Sat, 12 Sep 2020 20:54:13 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-send-sqs-messages-to-localstack-with-the-aws-java-sdk-20/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/blob/master/README.md">can be found on Github&lt;/a>.&lt;/p>
&lt;p>The completely rewritten &lt;a href="https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/welcome.html">AWS SDK for Java 2.0&lt;/a> comes with full reactive programming support all the way down. I wanted a way to test it out without spending any more or being at risk of spending too much money, so I used &lt;a href="https://github.com/localstack/localstack">localstack&lt;/a>. This post is largely walking you through what I came up with.&lt;/p></description></item><item><title>Continuous Subscriptions in Reactor</title><link>https://www.nickolasfisher.com/blog/continuous-subscriptions-in-reactor/</link><pubDate>Sat, 12 Sep 2020 17:14:10 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/continuous-subscriptions-in-reactor/</guid><description>&lt;p>There are use cases for wanting to immediately subscribe to a &lt;strong>Flux&lt;/strong> or a &lt;strong>Mono&lt;/strong> immediately after the subscription has completed. The most obvious use case is if your application needs to continuously poll for values.&lt;/p></description></item><item><title>A Guide to Automatic Retries in Reactor</title><link>https://www.nickolasfisher.com/blog/a-guide-to-automatic-retries-in-reactor/</link><pubDate>Sun, 16 Aug 2020 16:22:09 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-guide-to-automatic-retries-in-reactor/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux">is available on GitHub&lt;/a>.&lt;/p>
&lt;p>One of the nice things about a reactive programming model is there is a significantly lower risk of doomsday when things start getting latent all at once. You don&amp;rsquo;t have threads upstream blocking and waiting for a response, therefore they won&amp;rsquo;t all seize up and stop serving requests [or they won&amp;rsquo;t short circuit if you&amp;rsquo;re using a resiliency library like hystrix].&lt;/p></description></item><item><title>How to Setup SNS Message Forwarding to SQS with the AWS CLI</title><link>https://www.nickolasfisher.com/blog/how-to-setup-sns-message-forwarding-to-sqs-with-the-aws-cli/</link><pubDate>Sat, 15 Aug 2020 20:42:47 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-setup-sns-message-forwarding-to-sqs-with-the-aws-cli/</guid><description>&lt;p>&lt;a href="https://docs.aws.amazon.com/sns/latest/dg/welcome.html">Amazon SNS&lt;/a> is AWS&amp;rsquo;s solution to pub/sub. In a large, distributed system, decoupling &lt;em>events&lt;/em> from services that &lt;em>need to act on those events&lt;/em> allows for teams that own different services to better work in parallel, and also prevents the need for coordinating code deploys to deliver new features. If a services is already publishing a generic event, other services can hook into that event and act on them without needing anything but a bit of infrastructure.&lt;/p></description></item><item><title>How to use Mock Server to End to End Test Any WebClient Calls in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-use-mock-server-to-end-to-end-test-any-webclient-calls-in-spring-boot-webflux/</link><pubDate>Sat, 08 Aug 2020 22:44:14 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-mock-server-to-end-to-end-test-any-webclient-calls-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/mocking-and-unit-testing">can be found on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.mock-server.com">Mock Server&lt;/a> is a really simple and straightforward way to actually let your application make downstream calls and intercept them. That level of abstraction is really nice to have, and gives at least me much more confidence that my code is actually working in a microservices environment.&lt;/p></description></item><item><title>How to Mock Dependencies and Unit Test in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-mock-dependencies-and-unit-test-in-spring-boot-webflux/</link><pubDate>Sat, 08 Aug 2020 22:14:53 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-mock-dependencies-and-unit-test-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/mocking-and-unit-testing">on Github&lt;/a>.&lt;/p>
&lt;p>The most straightforward way to write unit tests in spring boot webflux is to leverage &lt;a href="https://projectreactor.io/docs/test/release/api/reactor/test/StepVerifier.html">project reactor&amp;rsquo;s StepVerifier&lt;/a>. StepVerifier allows you to pull each item in a &lt;strong>Flux&lt;/strong> or the only potential item in a &lt;strong>Mono&lt;/strong> and make assertions about each item as it&amp;rsquo;s pulled through the chain, or make assertions about certain errors that should be thrown in the process. I&amp;rsquo;m going to quickly walk you through an example integrating mockito with it and webflux.&lt;/p></description></item><item><title>OpenAPI and Spring Boot Webflux: A Working Introduction</title><link>https://www.nickolasfisher.com/blog/openapi-and-spring-boot-webflux-a-working-introduction/</link><pubDate>Sat, 01 Aug 2020 23:59:33 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/openapi-and-spring-boot-webflux-a-working-introduction/</guid><description>&lt;p>The &lt;a href="http://spec.openapis.org/oas/v3.0.3">OpenAPI Specification&lt;/a> is an &amp;ldquo;industry standard&amp;rdquo; way of declaring the API interface. As REST APIs using JSON have dominated the way we move data around in most organizations and on the internet, particularly in service oriented architectures, and as documentation at almost every company has been written once, read a couple of times, then lost to the wind, smart people have figured out that they can put the documentation for their services living with the code&amp;ndash;better yet, displayed while the app is running.&lt;/p></description></item><item><title>How to use Optimistic Locking in DynamoDB via the AWS CLI</title><link>https://www.nickolasfisher.com/blog/how-to-use-optimistic-locking-in-dynamodb-via-the-aws-cli/</link><pubDate>Sat, 01 Aug 2020 20:46:28 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-optimistic-locking-in-dynamodb-via-the-aws-cli/</guid><description>&lt;p>Optimistic Locking is a form of concurrency control that basically aims to prevent two different threads from accidentally overwriting data that another thread has already written. I covered &lt;a href="https://nickolasfisher.com/blog/Optimistic-Locking-in-MySQLExplain-Like-Im-Five">optimistic locking in MySQL&lt;/a> in a previous blog post, which may or may not be easier to understand based on your background.&lt;/p></description></item><item><title>DynamoDB Streams and Python: A Working Introduction</title><link>https://www.nickolasfisher.com/blog/dynamodb-streams-and-python-a-working-introduction/</link><pubDate>Sun, 26 Jul 2020 21:54:59 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/dynamodb-streams-and-python-a-working-introduction/</guid><description>&lt;p>DynamoDB Streams is AWS&amp;rsquo;s home grown &lt;a href="https://en.wikipedia.org/wiki/Change_data_capture">Change Data Capture [CDC]&lt;/a> mechanism, which allows the consumer of the stream to see records probably in approximately the order they were created [it&amp;rsquo;s basically impossible, at scale, to guarantee that all records across all partitions will somehow stream the data in exactly the same order that it was written]. This is a pretty fantastic feature because it allows us to reliably do &lt;em>&amp;mdash;something&amp;mdash;&lt;/em> after we add new data, update existing data, or delete existing data. As long as all the stream records are read and processed, we can ensure at least once processing on data changes and then go sleep soundly at night knowing that there is one less edge case in our application. Combine that with the natural scale that DynamoDB provides via its leaderless architecture and you can build this thing once and probably never have to worry about it handling more load ever again.&lt;/p></description></item><item><title>Optimistic Locking in MySQL--Explain Like I'm Five</title><link>https://www.nickolasfisher.com/blog/optimistic-locking-in-mysqlexplain-like-im-five/</link><pubDate>Sun, 26 Jul 2020 00:00:56 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/optimistic-locking-in-mysqlexplain-like-im-five/</guid><description>&lt;p>Optimistic Locking is a compromise to improve performance. If processors were infinitely fast, we wouldn&amp;rsquo;t need it and it would add unnecessary complexity. But, well, they aren&amp;rsquo;t.&lt;/p></description></item><item><title>How to Forward Request Headers to Downstream Services in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-forward-request-headers-to-downstream-services-in-spring-boot-webflux/</link><pubDate>Sun, 19 Jul 2020 19:39:10 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-forward-request-headers-to-downstream-services-in-spring-boot-webflux/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/reactive-programming-webflux/tree/master/context-api">can be found on Github&lt;/a>.&lt;/p>
&lt;p>When you make the switch to a reactive codebase, &lt;a href="https://docs.oracle.com/javase/7/docs/api/java/lang/ThreadLocal.html">ThreadLocal&lt;/a> becomes effectively off limits to you, because you aren&amp;rsquo;t guaranteed that the thread that starts the request processing remains the same, even if it&amp;rsquo;s the same HTTP request. This has caused pain in many places: the original implementation of spring security, for example, relied very heavily on ThreadLocal variables to store state that happened in the start of the request, and then reuse the information stored in those variables later on to make access control decisions. &lt;a href="https://netflixtechblog.com/zuul-2-the-netflix-journey-to-asynchronous-non-blocking-systems-45947377fb5c">Neflix spoke of their pain migrating to a reactive stack&lt;/a>, when they had relied so heavily on ThreadLocal variables in most of their shared libraries.&lt;/p></description></item><item><title>How to Return a Response Entity in Spring Boot Webflux</title><link>https://www.nickolasfisher.com/blog/how-to-return-a-response-entity-in-spring-boot-webflux/</link><pubDate>Sun, 19 Jul 2020 16:07:33 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-return-a-response-entity-in-spring-boot-webflux/</guid><description>&lt;p>In my last post on &lt;a href="https://nickolasfisher.com/blog/DynamoDB-and-Spring-Boot-Webflux-A-Working-Introduction">getting started with spring boot webflux and AWS DynamoDB&lt;/a>, I mentioned that it wasn&amp;rsquo;t immediately obvious to find a way to customize the response code in a spring boot &lt;strong>RestController&lt;/strong>, so I opted to use handlers instead.&lt;/p></description></item><item><title>DynamoDB and Spring Boot Webflux - A Working Introduction</title><link>https://www.nickolasfisher.com/blog/dynamodb-and-spring-boot-webflux-a-working-introduction/</link><pubDate>Sat, 18 Jul 2020 23:07:05 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/dynamodb-and-spring-boot-webflux-a-working-introduction/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/webflux-and-dynamo">can be found on Github&lt;/a>.&lt;/p>
&lt;p>The &lt;a href="https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/welcome.html">latest AWS SDK for java&lt;/a> uses a reactive client to send requests to various AWS services, including DynamoDB. Reactive programming is ultimately more robust at the edges&amp;ndash;once you start experiencing latency anywhere in your stack, if your tech is not reactive, you&amp;rsquo;re going to have a significantly worse time than if it were.&lt;/p></description></item><item><title>DynamoDB Basics: A Hands On Tutorial</title><link>https://www.nickolasfisher.com/blog/dynamodb-basics-a-hands-on-tutorial/</link><pubDate>Sun, 12 Jul 2020 18:36:05 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/dynamodb-basics-a-hands-on-tutorial/</guid><description>&lt;p>DynamoDB is a fully managed distributed datastore that does a great job of alleviating the operational overhead of building very scalable systems.&lt;/p></description></item><item><title>An Example Upgrade and Rollback of a Deployment image in Kubernetes</title><link>https://www.nickolasfisher.com/blog/an-example-upgrade-and-rollback-of-a-deployment-image-in-kubernetes/</link><pubDate>Sat, 20 Jun 2020 22:47:02 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/an-example-upgrade-and-rollback-of-a-deployment-image-in-kubernetes/</guid><description>&lt;p>In this article, I&amp;rsquo;m going to show you how to bootstrap a local kubernetes cluster with a custom image, debug it, deploy a new image, then rollback to the old image.&lt;/p></description></item><item><title>How to Setup and Use Kubernetes in Docker [kind]</title><link>https://www.nickolasfisher.com/blog/how-to-setup-and-use-kubernetes-in-docker-kind/</link><pubDate>Sat, 20 Jun 2020 19:32:30 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-setup-and-use-kubernetes-in-docker-kind/</guid><description>&lt;p>&lt;a href="https://kind.sigs.k8s.io/">kind&lt;/a> is a tool that spins up a kubernetes cluster of arbitrary size on your local machine. It is, in my experience, more lightweight than minikube, and also allows for a multi node setup.&lt;/p></description></item><item><title>How to Configure Rest Assured to Record the Latency of Every Request In a Custom Way</title><link>https://www.nickolasfisher.com/blog/how-to-configure-rest-assured-to-record-the-latency-of-every-request-in-a-custom-way/</link><pubDate>Sat, 13 Jun 2020 21:06:52 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-configure-rest-assured-to-record-the-latency-of-every-request-in-a-custom-way/</guid><description>&lt;p>Sample code associated with this post can be found &lt;a href="https://github.com/nfisher23/examples-testing-stuff">on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://github.com/rest-assured/rest-assured/wiki/Usage">Rest Assured&lt;/a> is a library that makes it easy to write api based automated tests in java. Recently I needed to find a way to record the latency of each request as well as some metadata about it [request path, method, things of that nature]. I found a nice way to do this with &lt;a href="https://github.com/rest-assured/rest-assured/wiki/Usage#filters">rest assured filters&lt;/a>, and I&amp;rsquo;m going to share that with you in this article.&lt;/p></description></item><item><title>The Hystrix Parameters You Actually Need to Tune in Spring Boot</title><link>https://www.nickolasfisher.com/blog/the-hystrix-parameters-you-actually-need-to-tune-in-spring-boot/</link><pubDate>Sat, 13 Jun 2020 17:53:33 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-hystrix-parameters-you-actually-need-to-tune-in-spring-boot/</guid><description>&lt;p>There is some [hacky] code for this post &lt;a href="https://github.com/nfisher23/hystrix-playground">on Github&lt;/a>.&lt;/p>
&lt;p>The &lt;a href="https://github.com/Netflix/Hystrix/wiki/Configuration">number of hystrix configuration options&lt;/a>, as of this writing, is about 34. In reality, you don&amp;rsquo;t need to worry about most of them, as the defaults are perfectly reasonable. This article discusses those parameters that, in my experience, you typically need to pay attention to and tune, and I have provided some examples using spring boot&amp;rsquo;s support for hystrix via the &lt;a href="https://github.com/Netflix/Hystrix/tree/master/hystrix-contrib/hystrix-javanica">javanica library&lt;/a>.&lt;/p></description></item><item><title>How to Configure Prometheus to Scrape and Aggregate Data From a Spring Boot 2.x Application</title><link>https://www.nickolasfisher.com/blog/how-to-configure-prometheus-to-scrape-and-aggregate-data-from-a-spring-boot-2x-application/</link><pubDate>Sat, 30 May 2020 20:33:50 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-configure-prometheus-to-scrape-and-aggregate-data-from-a-spring-boot-2x-application/</guid><description>&lt;p>You can see the source code for this post &lt;a href="https://github.com/nfisher23/prometheus-metrics-ex">on Github&lt;/a>.&lt;/p>
&lt;p>Following up on the last post [ &lt;a href="https://nickolasfisher.com/blog/How-to-Expose-Meaningful-Prometheus-Metrics-In-a-Spring-Boot-2x-Application">How to Expose Meaningful Prometheus Metrics In a Spring Boot 2.x Application&lt;/a>], if we have metrics exposed but they don&amp;rsquo;t go anywhere, are there metrics exposed at all?&lt;/p></description></item><item><title>How to Expose Meaningful Prometheus Metrics In a Spring Boot 2.x Application</title><link>https://www.nickolasfisher.com/blog/how-to-expose-meaningful-prometheus-metrics-in-a-spring-boot-2x-application/</link><pubDate>Sat, 30 May 2020 19:21:40 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-expose-meaningful-prometheus-metrics-in-a-spring-boot-2x-application/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/prometheus-metrics-ex">on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://prometheus.io/">Prometheus&lt;/a> is a metrics aggregator with its own presumed format. The basic idea is to have the application gather a set of custom metrics, then periodically collect (or &amp;ldquo;scrape&amp;rdquo;) the metrics and send them off to a prometheus server. This server will store the data in its database, and you can thus view the evolution of your application&amp;rsquo;s metrics over time.&lt;/p></description></item><item><title>How to Map Multiple Headers to the Same Variable in Nginx</title><link>https://www.nickolasfisher.com/blog/how-to-map-multiple-headers-to-the-same-variable-in-nginx/</link><pubDate>Sun, 24 May 2020 20:26:02 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-map-multiple-headers-to-the-same-variable-in-nginx/</guid><description>&lt;p>The &lt;a href="http://nginx.org/en/docs/http/ngx_http_map_module.html">nginx map module&lt;/a> is a nifty tool that allows you to programmatically change behavior based on things like http headers that come in.&lt;/p></description></item><item><title>A Concise Guide to Using Jasypt In Spring Boot for Configuration Encryption</title><link>https://www.nickolasfisher.com/blog/a-concise-guide-to-using-jasypt-in-spring-boot-for-configuration-encryption/</link><pubDate>Sat, 23 May 2020 01:58:12 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-concise-guide-to-using-jasypt-in-spring-boot-for-configuration-encryption/</guid><description>&lt;p>&lt;a href="http://www.jasypt.org/">Jasypt&lt;/a> is a simple encryption library. You can use it to encrypt anything, but one good use case is just encrypting your application configuration directly in your config file, so that if someone obtained access to your source control directory or had a copy of your source code, they would not also have access to any of your secrets.&lt;/p></description></item><item><title>How To Create a Kubernetes Cluster on Digital Ocean using Terraform</title><link>https://www.nickolasfisher.com/blog/how-to-create-a-kubernetes-cluster-on-digital-ocean-using-terraform/</link><pubDate>Sun, 17 May 2020 21:58:17 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-create-a-kubernetes-cluster-on-digital-ocean-using-terraform/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/digitalocean-terraform-examples/tree/master/kubernetes">on Github&lt;/a>.&lt;/p>
&lt;p>Kubernetes has democratized the cloud more than any piece of software before or since. What used to be proprietary APIs by AWS, Azure, or GCP for things like auto scaling groups, load balancers, or virtual machines is now abstracted away behind never ending yaml configuration. Combine this wonderful abstraction with the pricing model of &lt;a href="https://www.digitalocean.com/">Digital Ocean&lt;/a> and you&amp;rsquo;ve got all the makings of a developer party.&lt;/p></description></item><item><title>How to Create a Digital Ocean Droplet using Terraform</title><link>https://www.nickolasfisher.com/blog/how-to-create-a-digital-ocean-droplet-using-terraform/</link><pubDate>Sun, 17 May 2020 18:26:02 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-create-a-digital-ocean-droplet-using-terraform/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/digitalocean-terraform-examples">on Github&lt;/a>.&lt;/p>
&lt;p>Terraform lets you define your infrastructure, e.g. a virtual machine, in code. Used properly, this saves you a lot of time, makes infra easier to manage, and will generally limit your ability to do something dumb, like delete or modify something your infrastructure is dependent on.&lt;/p></description></item><item><title>The Difference Between a Reactive Non-Blocking Model and Classic Asynchronous Code</title><link>https://www.nickolasfisher.com/blog/the-difference-between-a-reactive-nonblocking-model-and-classic-asynchronous-code/</link><pubDate>Sat, 06 Jul 2019 15:10:01 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-difference-between-a-reactive-nonblocking-model-and-classic-asynchronous-code/</guid><description>&lt;p>Reactive Programming is a very different way of thinking about doing work in a microservices environment. Anyone who has worked with a GUI, dating back to even to windows forms, is familiar with the event based model, but what does that mean when there is unpredictable latency involved? How does handing off to a thread to make a remote call differ from this new &amp;ldquo;reactive web&amp;rdquo;?&lt;/p></description></item><item><title>How to Configure Reactive Netty in Spring Boot, in Depth</title><link>https://www.nickolasfisher.com/blog/how-to-configure-reactive-netty-in-spring-boot-in-depth/</link><pubDate>Sat, 06 Jul 2019 14:30:43 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-configure-reactive-netty-in-spring-boot-in-depth/</guid><description>&lt;p>&lt;a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html">Spring Boot&amp;rsquo;s WebFlux programming model&lt;/a> is pretty neat, but there isn&amp;rsquo;t a lot by way of explaining how to best leverage it to get the results you need. I wrote this blog post after tinkering with the configuration of Reactor Netty on Spring Boot.&lt;/p></description></item><item><title>How to Make Concurrent Service API Calls in Java Using Spring Boot</title><link>https://www.nickolasfisher.com/blog/how-to-make-concurrent-service-api-calls-in-java-using-spring-boot/</link><pubDate>Sat, 22 Jun 2019 20:48:30 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-make-concurrent-service-api-calls-in-java-using-spring-boot/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/java-concurrency-examples/tree/master">on GitHub&lt;/a>.&lt;/p>
&lt;p>When you&amp;rsquo;re in a microservice environment, it often makes sense to make some calls to multiple services at the same time. This allows for the time an operation needs to complete to be reduced from the &lt;em>sum&lt;/em> of all the time spent waiting to the &lt;em>maximum&lt;/em> time spent over the span of calls.&lt;/p></description></item><item><title>How to Authenticate Against a Spring Boot Service Using JWT</title><link>https://www.nickolasfisher.com/blog/how-to-authenticate-against-a-spring-boot-service-using-jwt/</link><pubDate>Sat, 22 Jun 2019 20:29:27 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-authenticate-against-a-spring-boot-service-using-jwt/</guid><description>&lt;p>havent written it&lt;/p></description></item><item><title>How to Create Multiple Digital Ocean Droplets and Provision Them Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-create-multiple-digital-ocean-droplets-and-provision-them-using-ansible/</link><pubDate>Sun, 16 Jun 2019 17:14:49 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-create-multiple-digital-ocean-droplets-and-provision-them-using-ansible/</guid><description>&lt;p>In a previous post, we saw &lt;a href="https://nickolasfisher.com/blog/How-To-Create-a-Digital-Ocean-Droplet-and-Provision-It-Using-Ansible">how to create a digital ocean droplet and provision it with Ansible&lt;/a>. Creating multiple droplets is very similar, you mostly just have to pay attention to the response object that you get back, which is different in the single vs. the many case.&lt;/p></description></item><item><title>How To Create a Digital Ocean Droplet and Provision It Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-create-a-digital-ocean-droplet-and-provision-it-using-ansible/</link><pubDate>Sat, 15 Jun 2019 20:40:48 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-create-a-digital-ocean-droplet-and-provision-it-using-ansible/</guid><description>&lt;p>Ansible allows you to provision servers in an idempotent fashion. It lets you see the state of your VM configuration as it resides in code, which is light years better than the sysadmin ways of yesterday.&lt;/p></description></item><item><title>How to Run a Script on Cluster State Change Using Consul Watch</title><link>https://www.nickolasfisher.com/blog/how-to-run-a-script-on-cluster-state-change-using-consul-watch/</link><pubDate>Sat, 25 May 2019 22:18:42 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-run-a-script-on-cluster-state-change-using-consul-watch/</guid><description>&lt;p>You can see the sample code for this post &lt;a href="https://github.com/nfisher23/some-ansible-examples/tree/master/consul-server">on Github&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.consul.io/docs/agent/watches.html">Consul Watches&lt;/a> offer a way to hook into changes to the Consul cluster state at runtime.The specific type of changes we will be looking at hooking into in this post are &lt;a href="https://www.consul.io/docs/agent/watches.html#type-checks">checks&lt;/a>. Whenever a node or service comes online and registers to Consul, whenever an existing node or service leaves Consul, or whenever an existing node or service becomes unresponsive, Consul will emit a check event. This check event can invoke a process to monitor the health of our services, alerting human being that action might soon be necessary.&lt;/p></description></item><item><title>How to Register a Spring Boot Service to a Consul Cluster</title><link>https://www.nickolasfisher.com/blog/how-to-register-a-spring-boot-service-to-a-consul-cluster/</link><pubDate>Sat, 25 May 2019 16:24:46 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-register-a-spring-boot-service-to-a-consul-cluster/</guid><description>&lt;p>In a previous post, we saw &lt;a href="https://nickolasfisher.com/blog/How-to-Provision-a-Consul-ClientServer-Cluster-using-Ansible">how to provision a simple consul client/server cluster using Ansible&lt;/a>. We will now look at interacting with that cluster by showing how to register a spring boot application to it, using &lt;a href="https://cloud.spring.io/spring-cloud-consul/spring-cloud-consul.html">spring cloud consul&lt;/a>.&lt;/p></description></item><item><title>How to Selectively Allow Cross Origin Resource Sharing in Spring Boot</title><link>https://www.nickolasfisher.com/blog/how-to-selectively-allow-cross-origin-resource-sharing-in-spring-boot/</link><pubDate>Sat, 18 May 2019 19:12:46 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-selectively-allow-cross-origin-resource-sharing-in-spring-boot/</guid><description>&lt;p>A single page application (SPA) architecture usually involves an end user getting a smattering of javascript files when he/she makes a request to a URL endpoint. After the javascript files load and start executing code, they usually make AJAX calls to interact with the back end from that point onwards. This pairs nicely with a microservice architecture based on REST over HTTP, since the front end SPA can effectively act as a client to any microservice that it needs information from.&lt;/p></description></item><item><title>A Fast SCSS Learning Feedback Loop With Harp and BrowserSync</title><link>https://www.nickolasfisher.com/blog/a-fast-scss-learning-feedback-loop-with-harp-and-browsersync/</link><pubDate>Sat, 18 May 2019 17:12:55 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-fast-scss-learning-feedback-loop-with-harp-and-browsersync/</guid><description>&lt;p>If, like me, your development career has been firmly on servers, wiring and protecting data across multiple machine and focusing on architecture, the shift to building websites that &amp;ldquo;look right&amp;rdquo; can sometimes be a tough transition. Like all things engineering, ensuring that you have a short feedback loop, where you can interact with the tool that you&amp;rsquo;re using in a very hands on way, will be your fastest and surest way to mastery.&lt;/p></description></item><item><title>How to Provision a Consul Client-Server Cluster using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-provision-a-consul-clientserver-cluster-using-ansible/</link><pubDate>Sat, 27 Apr 2019 21:15:18 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-a-consul-clientserver-cluster-using-ansible/</guid><description>&lt;p>The source code for this blog post can be found &lt;a href="https://github.com/nfisher23/some-ansible-examples/tree/master/consul-server">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.consul.io">Consul&lt;/a> can run in either client or server mode. As far as Consul is concerned, the primary difference between client and server mode are that Consul Servers participate in the consensus quorum, store cluster state, and handle queries. Consul Agents are often deployed to act as middle-men between the services and the Consul Servers, which need to be highly available by design.&lt;/p></description></item><item><title>How to Provision a Standalone Consul Server with Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-provision-a-standalone-consul-server-with-ansible/</link><pubDate>Sat, 27 Apr 2019 19:49:14 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-a-standalone-consul-server-with-ansible/</guid><description>&lt;p>You can find the source code for this post &lt;a href="https://github.com/nfisher23/some-ansible-examples/tree/master/consul-server">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.consul.io/">Consul&lt;/a> is a distributed service discovery engine. It&amp;rsquo;s primary purpose is to track and manage services that interact with it&amp;ndash;usually via an HTTP API. It monitors the health of services in near real time, providing a more robust way of routing services to healthy and responsive nodes.&lt;/p></description></item><item><title>How to Migrate a Real PostgreSQL Database Using Flyway with Spring Boot</title><link>https://www.nickolasfisher.com/blog/how-to-migrate-a-real-postgresql-database-using-flyway-with-spring-boot/</link><pubDate>Sat, 20 Apr 2019 16:37:18 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-migrate-a-real-postgresql-database-using-flyway-with-spring-boot/</guid><description>&lt;p>You can see the source code for this post &lt;a href="https://github.com/nfisher23/postgres-flyway-example">on GitHub&lt;/a>.&lt;/p>
&lt;p>We spent the last post figuring out &lt;a href="https://nickolasfisher.com/blog/How-to-Migrate-An-Embedded-PostgreSQL-Database-Using-Flyway-in-Spring-Boot">how to migrate an embedded PostgreSQL database using Spring&lt;/a>, while trying to side-step the extra magic that comes along with the framework. Here, we are going to build on that work to migrate a real PostgreSQL instance, which we will build in a local Vagrant Virtual Machine.&lt;/p></description></item><item><title>How to Migrate An Embedded PostgreSQL Database Using Flyway in Spring Boot</title><link>https://www.nickolasfisher.com/blog/how-to-migrate-an-embedded-postgresql-database-using-flyway-in-spring-boot/</link><pubDate>Sat, 20 Apr 2019 16:00:34 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-migrate-an-embedded-postgresql-database-using-flyway-in-spring-boot/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/postgres-flyway-example">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://flywaydb.org/">Flyway&lt;/a> is a database migration tool. &lt;em>Migrating&lt;/em> a database generally means that you are making a change to the way the database currently structures its data. It could also mean you are adding stuff like custom stored procedures or indexes to help speed up queries. Either way, migrating databases is easily the most difficult part of any deployment strategy&amp;ndash;Flyway makes this process as painless as possible because it will, by default, &lt;em>only run migration scripts that haven&amp;rsquo;t yet run&lt;/em>.&lt;/p></description></item><item><title>How to Create an Embedded PostgreSQL Database With Spring Boot</title><link>https://www.nickolasfisher.com/blog/how-to-create-an-embedded-postgresql-database-with-spring-boot/</link><pubDate>Sat, 20 Apr 2019 15:28:25 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-create-an-embedded-postgresql-database-with-spring-boot/</guid><description>&lt;p>You can see the sample code for this post &lt;a href="https://github.com/nfisher23/postgres-flyway-example">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.postgresql.org/">PostgreSQL&lt;/a> is still my favorite database, and if a project I&amp;rsquo;m working on makes sense as a relational database model, it&amp;rsquo;s always what I reach for.&lt;/p></description></item><item><title>How To Invalidate an Nginx Cache In a Reverse Proxy Setup With Spring MVC</title><link>https://www.nickolasfisher.com/blog/how-to-invalidate-an-nginx-cache-in-a-reverse-proxy-setup-with-spring-mvc/</link><pubDate>Sat, 13 Apr 2019 16:52:53 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-invalidate-an-nginx-cache-in-a-reverse-proxy-setup-with-spring-mvc/</guid><description>&lt;p>You can see the sample code associated with this post &lt;a href="https://github.com/nfisher23/some-ansible-examples/tree/master/reverse-proxy-nginx">on Github&lt;/a>.&lt;/p>
&lt;p>In two previous posts, we looked at how to &lt;a href="https://nickolasfisher.com/blog/How-to-Deploy-a-Spring-MVC-Application-Behind-an-Nginx-Reverse-Proxy">provision a reverse proxy using nginx&lt;/a> and then &lt;a href="https://nickolasfisher.com/blog/How-to-Use-Nginxs-Caching-to-Improve-Site-Responsiveness">how to add caching to the nginx reverse proxy&lt;/a>. The implementation we ended up with at the end of the last post was a &amp;ldquo;dumb&amp;rdquo; cache, meaning that it doesn&amp;rsquo;t know when or if any data gets updated&amp;ndash;it just times out after 60 seconds and then asks for a new payload from the application it&amp;rsquo;s acting as proxy for.&lt;/p></description></item><item><title>How to Use Nginx's Caching to Improve Site Responsiveness</title><link>https://www.nickolasfisher.com/blog/how-to-use-nginxs-caching-to-improve-site-responsiveness/</link><pubDate>Sat, 06 Apr 2019 17:14:30 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-nginxs-caching-to-improve-site-responsiveness/</guid><description>&lt;p>The source code for this post &lt;a href="https://github.com/nfisher23/some-ansible-examples/tree/master/reverse-proxy-nginx">can be found on Github&lt;/a>.&lt;/p>
&lt;p>In my last post, I provided an example for &lt;a href="https://nickolasfisher.com/blog/How-to-Deploy-a-Spring-MVC-Application-Behind-an-Nginx-Reverse-Proxy">how to set up an Nginx Reverse Proxy for a Spring MVC application&lt;/a>. One such reason to set up a reverse proxy is to utilize caching of resources. If you have dynamically generated content that doesn&amp;rsquo;t change very often, then adding caching at the site entry point can dramatically improve site responsiveness and reduce load on critical resources.&lt;/p></description></item><item><title>How to Deploy a Spring MVC Application Behind an Nginx Reverse Proxy</title><link>https://www.nickolasfisher.com/blog/how-to-deploy-a-spring-mvc-application-behind-an-nginx-reverse-proxy/</link><pubDate>Sat, 06 Apr 2019 14:44:50 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-deploy-a-spring-mvc-application-behind-an-nginx-reverse-proxy/</guid><description>&lt;p>&lt;a href="https://www.nginx.com/">Nginx&lt;/a> is a popular webserver, excellent at serving up static content, and commonly used as a load balancer or reverse proxy. This post will set up a basic &lt;a href="https://spring.io/projects/spring-boot">Spring Boot&lt;/a> MVC web application, and use Nginx as a reverse proxy. The source code can be found &lt;a href="https://github.com/nfisher23/some-ansible-examples/tree/master/reverse-proxy-nginx">on GitHub&lt;/a>.&lt;/p></description></item><item><title>How To Upgrade Kibana using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-upgrade-kibana-using-ansible/</link><pubDate>Sat, 23 Mar 2019 21:14:22 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-upgrade-kibana-using-ansible/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub&lt;/a>.&lt;/p>
&lt;p>In a previous post on &lt;a href="https://nickolasfisher.com/blog/How-to-Provision-a-Linux-VM-With-Kibana-Using-Ansible">Provisioning a Server with Kibana&lt;/a>, we saw that it&amp;rsquo;s very straightforward to get kibana on a box.&lt;/p></description></item><item><title>How to do a Rolling Upgrade of Multiple Logstash Instances Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-do-a-rolling-upgrade-of-multiple-logstash-instances-using-ansible/</link><pubDate>Sun, 17 Mar 2019 23:27:43 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-do-a-rolling-upgrade-of-multiple-logstash-instances-using-ansible/</guid><description>&lt;p>You can see the source code for this post &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub&lt;/a>.&lt;/p>
&lt;p>In a previous post on &lt;a href="https://nickolasfisher.com/blog/How-to-Provision-Multiple-Logstash-Hosts-Using-Ansible">How to Provision Multiple Logstash Hosts Using Ansible&lt;/a>, we saw that provisioning logstash is pretty straightforward. However, what do we do with it after it&amp;rsquo;s been out there transforming messages this entire time? Given that elastic comes out with a new version of Logstash every fifteen or twenty minutes, a wise person would look to automate the upgrade process as soon as possible.&lt;/p></description></item><item><title>How to do a Rolling Upgrade of an Elasticsearch Cluster Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-do-a-rolling-upgrade-of-an-elasticsearch-cluster-using-ansible/</link><pubDate>Sat, 16 Mar 2019 23:17:03 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-do-a-rolling-upgrade-of-an-elasticsearch-cluster-using-ansible/</guid><description>&lt;p>You can see the source code for this blog post &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub&lt;/a>.&lt;/p>
&lt;p>In a previous post, we saw &lt;a href="https://nickolasfisher.com/blog/How-to-Provision-a-Multi-Node-Elasticsearch-Cluster-Using-Ansible">how to provision a multi-node elasticsearch cluster using ansible&lt;/a>. The problem with that post is that, by the time I was done writing it, &lt;em>Elastic had already come out with a new version of elasticsearch&lt;/em>. I&amp;rsquo;m being mildly facetious, but not really. They release new versions very quickly, even by the standards of modern software engineering.&lt;/p></description></item><item><title>How to Provision a Linux VM With Kibana Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-provision-a-linux-vm-with-kibana-using-ansible/</link><pubDate>Sat, 16 Mar 2019 15:37:40 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-a-linux-vm-with-kibana-using-ansible/</guid><description>&lt;p>The corresponding source code for this post is available &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.elastic.co/products/kibana">Kibana&lt;/a> is a fancy pants web application that tries to make data in Elasticsearch user-friendly. Rounding out the previous two posts on &lt;a href="https://nickolasfisher.com/blog/How-to-Provision-a-Multi-Node-Elasticsearch-Cluster-Using-Ansible">how to install an elasticsearch cluster&lt;/a> and &lt;a href="https://nickolasfisher.com/blog/How-to-Install-Multiple-Logstash-Hosts-Using-Ansible">how to install multiple logstash hosts&lt;/a>, I will now show you how to stack kibana on top of them.&lt;/p></description></item><item><title>How to Provision Multiple Logstash Hosts Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-provision-multiple-logstash-hosts-using-ansible/</link><pubDate>Wed, 06 Mar 2019 23:33:35 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-multiple-logstash-hosts-using-ansible/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://www.elastic.co/products/logstash">Logstash&lt;/a> primarily exists to extract useful information out of plain-text logs. Most applications have custom logs which are in whatever format the person writing them thought would look reasonable&amp;hellip;usually to a human, and not to a machine. While countless future developer hours would be preserved if everything were just in JSON, that is sadly not even remotely the case, and in particular it&amp;rsquo;s not the case for log files. Logstash aims to be the intermediary between the various log formats and Elasticsearch, which is the document database provided by Elastic as well.&lt;/p></description></item><item><title>How to Provision a Multi Node Elasticsearch Cluster Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-provision-a-multi-node-elasticsearch-cluster-using-ansible/</link><pubDate>Sun, 03 Mar 2019 23:15:27 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-a-multi-node-elasticsearch-cluster-using-ansible/</guid><description>&lt;p>You can see the sample code for this tutorial &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub.&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.elastic.co/products/elasticsearch">Elasticsearch&lt;/a> is a distributed, NoSQL, document database, built on top of Lucene. There are so many things I could say about Elasticsearch, but instead I&amp;rsquo;ll focus on how to install a simple 3-node cluster with an Ansible role. The following example will not have any security baked into it, so it&amp;rsquo;s really just a starting point to get you up and running.&lt;/p></description></item><item><title>How to do Test Driven Development on Your Ansible Roles Using Molecule</title><link>https://www.nickolasfisher.com/blog/how-to-do-test-driven-development-on-your-ansible-roles-using-molecule/</link><pubDate>Sun, 03 Mar 2019 20:18:22 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-do-test-driven-development-on-your-ansible-roles-using-molecule/</guid><description>&lt;p>You can see the sample code for this tutorial &lt;a href="https://github.com/nfisher23/some-ansible-examples">on GitHub.&lt;/a>&lt;/p>
&lt;p> &lt;a href="https://molecule.readthedocs.io/en/latest/">Molecule&lt;/a> is primarily a way to manage the testing of infrastructure automation code. At its core, it wraps around various providers like Vagrant, Docker, or VMWare, and provides relatively simple integration with testing providers, notably &lt;a href="https://testinfra.readthedocs.io/en/latest/">TestInfra&lt;/a>. Molecule is a great tool, but in my opinion there are not enough resources, by way of examples, to provide an adequate getting started guide. This post is meant to help fill that void.&lt;/p></description></item><item><title>Exploring Lombok: How to use @Builder, @Accessors, and @Wither for POJO Classes</title><link>https://www.nickolasfisher.com/blog/exploring-lombok-how-to-use-builder-accessors-and-wither-for-pojo-classes/</link><pubDate>Sat, 09 Feb 2019 15:50:55 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/exploring-lombok-how-to-use-builder-accessors-and-wither-for-pojo-classes/</guid><description>&lt;p>&lt;a href="https://projectlombok.org/">Lombok&lt;/a> manipulates the output java bytecode .class files, and inserts boilerplate code that java developers are very familiar with repeating themselves on.&lt;/p></description></item><item><title>How to run a SQL Script Against a Postgres Database Using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-run-a-sql-script-against-a-postgres-database-using-ansible/</link><pubDate>Sat, 09 Feb 2019 15:44:26 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-run-a-sql-script-against-a-postgres-database-using-ansible/</guid><description>&lt;p>The source code for this post can be found &lt;a href="https://github.com/nfisher23/run-sql-ansible-postgres">on GitHub&lt;/a>.&lt;/p>
&lt;p>Managing a live database, and in particular dealing with database migrations without allowing for any downtime in your application, is typically the most challenging part of any automated deployment strategy. Services can be spun up and down with impunity because their state at the beginning and at the end are exactly the same, but databases store data&amp;ndash;their state is always changing.&lt;/p></description></item><item><title>Antifragile, by Nassim Nicholas Taleb: Summary In Quotes</title><link>https://www.nickolasfisher.com/blog/antifragile-by-nassim-nicholas-taleb-summary-in-quotes/</link><pubDate>Sun, 16 Dec 2018 08:06:43 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/antifragile-by-nassim-nicholas-taleb-summary-in-quotes/</guid><description>&lt;p>Antifragile, by Nassim Nicholas Taleb, presents a truly unique viewpoint about the world. While there are many things here that are far fetched, there is far more that is very sound in its analysis. Even if you disagree with everything in it, this book&amp;rsquo;s usefulness, in the form of working theories about how to survive in the world, will prove itself very apparent.&lt;/p></description></item><item><title>Next, by Michael Lewis: Summary In Quotes</title><link>https://www.nickolasfisher.com/blog/next-by-michael-lewis-summary-in-quotes/</link><pubDate>Sun, 16 Dec 2018 05:57:32 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/next-by-michael-lewis-summary-in-quotes/</guid><description>&lt;p>Next, by Michael Lewis, is probably my least favorite book my him. Regardless, I&amp;rsquo;m convinced that he&amp;rsquo;s in his own league, so Next is still an excellent book.&lt;/p></description></item><item><title>Behind The Cloud: Summary In Quotes</title><link>https://www.nickolasfisher.com/blog/behind-the-cloud-summary-in-quotes/</link><pubDate>Sun, 16 Dec 2018 00:49:43 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/behind-the-cloud-summary-in-quotes/</guid><description>&lt;p>Behind the Cloud, by Marc Benioff, is his own story about how Salesforce became one of the first software-as-a-subscription services. While it honestly sometimes felt like another marketing ploy for Salesforce, there were many nuggets of wisdom to take out of it.&lt;/p></description></item><item><title>Java Date and Time: Instant, LocalDate, and TemporalAdjuster</title><link>https://www.nickolasfisher.com/blog/java-date-and-time-instant-localdate-and-temporaladjuster/</link><pubDate>Sat, 01 Dec 2018 12:56:02 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/java-date-and-time-instant-localdate-and-temporaladjuster/</guid><description>&lt;p>Improvements to the Java 8 &lt;a href="https://docs.oracle.com/javase/tutorial/datetime/iso/index.html">Date and Time API&lt;/a>&amp;ndash;in particular Instant, LocalDate/LocalDateTime, and their absolute counterpart ZonedDateTime, provide a much more intuitive and friendly way to deal with time than previous versions of Java.&lt;/p></description></item><item><title>A Simple Zero Downtime Continuous Integration Pipeline for Spring MVC</title><link>https://www.nickolasfisher.com/blog/a-simple-zero-downtime-continuous-integration-pipeline-for-spring-mvc/</link><pubDate>Sun, 25 Nov 2018 15:53:22 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-simple-zero-downtime-continuous-integration-pipeline-for-spring-mvc/</guid><description>&lt;p>The sample code associated with what follows can be found &lt;a href="https://github.com/nfisher23/simple-cicd-pipeline-with-spring">on GitHub&lt;/a>.&lt;/p>
&lt;p>One of the biggest paradigm shifts in software engineering, since the invention of the computer and software that would run on it, was the idea of a MVR (minimum viable release) or MVP (minimum viable product). With the lack of internet access becoming the exception in developed countries, it becomes more and more powerful to put your product out there on display, and to design a way to continuously make improvements to it. In the most aggressive of circumstances, you want to be able to push something up to a source control server, then let an automated process perform the various steps required to actually deploy it in the real world. In the best case, you can achieve all of this with zero downtime&amp;ndash;basically, the users of your service are never inconvenienced by your decision to make a change. Setting up one very simple example of that is the subject of this post.&lt;/p></description></item><item><title>Use First Class Functions to Reduce Code Duplication In Java</title><link>https://www.nickolasfisher.com/blog/use-first-class-functions-to-reduce-code-duplication-in-java/</link><pubDate>Sat, 24 Nov 2018 19:03:21 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/use-first-class-functions-to-reduce-code-duplication-in-java/</guid><description>&lt;p>Often when we program, we find ourselves creating patterns, usually in the form of boilerplate code, that seem to always do the same thing. For example, let&amp;rsquo;s say you have some logging logic that is non-trivial, and you want to make extra sure you don&amp;rsquo;t blow up your main application while it&amp;rsquo;s running, so you surround it with a try/catch block:&lt;/p></description></item><item><title>How to Use Spring's Dependency Injection in Setup And Teardown Code For Integration Tests With Maven</title><link>https://www.nickolasfisher.com/blog/how-to-use-springs-dependency-injection-in-setup-and-teardown-code-for-integration-tests-with-maven/</link><pubDate>Sat, 24 Nov 2018 15:51:32 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-springs-dependency-injection-in-setup-and-teardown-code-for-integration-tests-with-maven/</guid><description>&lt;p>You can view the sample code for this repository &lt;a href="https://github.com/nfisher23/integration-testing-postgres-and-spring">on GitHub&lt;/a>.&lt;/p>
&lt;p>In our last post on &lt;a href="https://nickolasfisher.com/blog/How-to-Run-Integration-Tests-with-Setup-and-Teardown-Code-in-Maven-Build">Using Maven to Setup and Teardown Integration Tests&lt;/a>, we saw how to run Java code before and after our integration tests to setup and teardown any data that our tests depended on. What if we are using Spring, and we want to use our ApplicationContext, and its dependency injection/property injection features? After all, we would be testing the configuration for our specific application more than anything else, so we should be certain to use it in our setup and teardown code.&lt;/p></description></item><item><title>How to Run Integration Tests with Setup and Teardown Code in Maven Build</title><link>https://www.nickolasfisher.com/blog/how-to-run-integration-tests-with-setup-and-teardown-code-in-maven-build/</link><pubDate>Sat, 24 Nov 2018 14:49:09 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-run-integration-tests-with-setup-and-teardown-code-in-maven-build/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/integration-testing-postgres-and-spring">on GitHub&lt;/a>.&lt;/p>
&lt;p>Unit testing with Maven is built in, and is the preferred way of validating code is performing correctly. However, sometimes you need integration testing, and most non-trivial applications built in the 21st century are reliant on network connections and databases&amp;ndash;that is, things which are inherently third party to your application. If you don&amp;rsquo;t adequately take that to account in your CI/CD pipeline, you might end up discovering that something very bad has happened after damage has already been done.&lt;/p></description></item><item><title>How to Set Up a Local Unsecured Postgres Virtual Machine (for testing)</title><link>https://www.nickolasfisher.com/blog/how-to-set-up-a-local-unsecured-postgres-virtual-machine-for-testing/</link><pubDate>Sat, 24 Nov 2018 12:47:47 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-set-up-a-local-unsecured-postgres-virtual-machine-for-testing/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/integration-testing-postgres-and-spring/tree/master/postgres-vm-sandbox">on GitHub&lt;/a>.&lt;/p>
&lt;p>While we can always install &lt;a href="https://www.postgresql.org/">PostgreSQL&lt;/a> on our host machine, it&amp;rsquo;s a much cleaner solution to create something like a local virtual machine with &lt;a href="https://www.vagrantup.com/">Vagrant&lt;/a> or a container using &lt;a href="https://www.docker.com/">Docker.&lt;/a> That way, any changes we make to the database and then forget about are not around as soon as we destroy either the container or the virtual machine. It is one more way to tighten that feedback loop we need as developers.&lt;/p></description></item><item><title>How to Provision a Server with Java using Ansible</title><link>https://www.nickolasfisher.com/blog/how-to-provision-a-server-with-java-using-ansible/</link><pubDate>Sun, 18 Nov 2018 17:15:01 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-a-server-with-java-using-ansible/</guid><description>&lt;p>In my post about &lt;a href="https://nickolasfisher.com/blog/How-to-Provision-a-Linux-Server-With-Any-Version-of-Java-via-a-Bash-Script">how to provision any version of Java using a bash script&lt;/a>, we saw that:&lt;/p></description></item><item><title>How to Use Spring's Aspect Oriented Programming to log all Public Methods</title><link>https://www.nickolasfisher.com/blog/how-to-use-springs-aspect-oriented-programming-to-log-all-public-methods/</link><pubDate>Sun, 18 Nov 2018 14:40:55 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-use-springs-aspect-oriented-programming-to-log-all-public-methods/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/spring-aop-universal-public-logger">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://docs.spring.io/spring/docs/2.5.x/reference/aop.html">Aspect Oriented Programming In Spring&lt;/a> is a clever way to reduce code duplication, by taking a different approach than traditional tools like dependency injection or inheritance. Cross cutting concerns like security and logging can permeate a code base and make maintainability a nightmare unless properly taken care of, and aspect oriented programming is one way to properly take care of that, when used appropriately. This post will illustrate how to get started with a transparent way to log without cluttering up business logic.&lt;/p></description></item><item><title>A VagrantFile for Elasticsearch, Logstash, and Kibana (On Three Different Servers)</title><link>https://www.nickolasfisher.com/blog/a-vagrantfile-for-elasticsearch-logstash-and-kibana-on-three-different-servers/</link><pubDate>Sun, 18 Nov 2018 13:42:46 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/a-vagrantfile-for-elasticsearch-logstash-and-kibana-on-three-different-servers/</guid><description>&lt;p>&lt;a href="https://www.elastic.co/">Elasticsearch, Logstash, and Kibana&lt;/a>, commonly referred to as ELK or the Elastic Stack, is a set of tools that can, well do a lot of things. It is most famous for its logging and analytics capabilities.&lt;/p></description></item><item><title>How to Dynamically Deserialize JSON In Java With Jackson</title><link>https://www.nickolasfisher.com/blog/how-to-dynamically-deserialize-json-in-java-with-jackson/</link><pubDate>Sun, 18 Nov 2018 12:45:53 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-dynamically-deserialize-json-in-java-with-jackson/</guid><description>&lt;p>You can find the sample code associated with this blog post &lt;a href="https://github.com/nfisher23/json-with-jackson-tricks">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://github.com/FasterXML/jackson">Jackson&lt;/a> is a data processor in Java, known particularly well for its ability to deal with JSON payloads.&lt;/p></description></item><item><title>Improving Java IO Performance: Caching Data, When Appropriate</title><link>https://www.nickolasfisher.com/blog/improving-java-io-performance-caching-data-when-appropriate/</link><pubDate>Sat, 17 Nov 2018 19:16:28 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/improving-java-io-performance-caching-data-when-appropriate/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/io-tuning">on GitHub&lt;/a>.&lt;/p>
&lt;p>The biggest bottleneck with I/O resources on the filesystem is the operating system, which controls access to the filesystem. Reading from, and writing to, the operating system, is much more expensive than storing data in memory, and that is the subject of this post: caching.&lt;/p></description></item><item><title>Improving Java IO Performance: Does Compression Actually Help?</title><link>https://www.nickolasfisher.com/blog/improving-java-io-performance-does-compression-actually-help/</link><pubDate>Sat, 17 Nov 2018 18:55:03 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/improving-java-io-performance-does-compression-actually-help/</guid><description>&lt;p>The sample code associated with this blog post can be found &lt;a href="https://github.com/nfisher23/io-tuning">on GitHub&lt;/a>.&lt;/p>
&lt;p>The question &amp;ldquo;does compression actually help?&amp;rdquo; is admittedly pretty loaded. The real answer is &lt;em>sometimes&lt;/em>, and &lt;em>it depends&lt;/em>. I will not try to answer every use case, but I will provide a very specific example here that appears to provide a &amp;ldquo;probably not&amp;rdquo; answer (for this specific use case).&lt;/p></description></item><item><title>Improving Java IO Performance: Appropriately Using Random Access Over Streams</title><link>https://www.nickolasfisher.com/blog/improving-java-io-performance-appropriately-using-random-access-over-streams/</link><pubDate>Sat, 17 Nov 2018 18:37:39 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/improving-java-io-performance-appropriately-using-random-access-over-streams/</guid><description>&lt;p>The sample code for this blog post can be found &lt;a href="https://github.com/nfisher23/io-tuning">on GitHub&lt;/a>.&lt;/p>
&lt;p>A flavor I/O performance optimization that applies specifically to the filesystem is the decision on when to use Random Access instead of something like a BufferedInputStream. Random access allows for accessing a file in a similar way as a large array of bytes stored on the filesystem. From the &lt;a href="https://docs.oracle.com/javase/7/docs/api/java/io/RandomAccessFile.html">oracle documentation on the RandomAccessFile class&lt;/a>:&lt;/p></description></item><item><title>Improving Java IO Performance: Formatting Costs</title><link>https://www.nickolasfisher.com/blog/improving-java-io-performance-formatting-costs/</link><pubDate>Sat, 17 Nov 2018 18:27:31 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/improving-java-io-performance-formatting-costs/</guid><description>&lt;p>The sample code associated with this blog post can be found &lt;a href="https://github.com/nfisher23/io-tuning">on GitHub&lt;/a>.&lt;/p>
&lt;p>Another potential source of I/O bottlenecks, across any medium, could be the process you choose to format the data in in the first place. For example, XML used to be a standard way to send information across the wire or store in a backend system, but the size overhead of XML as compared to JSON is about double (not to mention it&amp;rsquo;s somehow harder to read when formatted compared to JSON).&lt;/p></description></item><item><title>Improving Java IO Performance: Reducing Method Call Overhead</title><link>https://www.nickolasfisher.com/blog/improving-java-io-performance-reducing-method-call-overhead/</link><pubDate>Sat, 17 Nov 2018 18:06:13 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/improving-java-io-performance-reducing-method-call-overhead/</guid><description>&lt;p>You can view the sample code associated with this blog post &lt;a href="https://github.com/nfisher23/io-tuning">on GitHub.&lt;/a>&lt;/p>
&lt;p>While you can achieve massive improvements in I/O operations via &lt;a href="https://nickolasfisher.com/blog/Improving-Java-IO-Performance-Buffering-Techniques">buffering&lt;/a>, another key part of tuning java code in general, which is applicable to I/O bound operations, is method call overhead. Methods that are unnecessarily called repeatedly can bog down operations.&lt;/p></description></item><item><title>Improving Java IO Performance: Buffering Techniques</title><link>https://www.nickolasfisher.com/blog/improving-java-io-performance-buffering-techniques/</link><pubDate>Sat, 10 Nov 2018 12:45:54 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/improving-java-io-performance-buffering-techniques/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/io-tuning">on GitHub&lt;/a>.&lt;/p>
&lt;p>Now that we know &lt;a href="https://nickolasfisher.com/blog/How-to-Benchmark-Java-Code-Using-JUnit-and-JMH">how to benchmark using junit and jmh&lt;/a>, let&amp;rsquo;s put it to the test and try to optimize some basic I/O operations. While filesystem tasks are much less common in the web-enabled world, understanding the basics can help us when we move on to streams across network connections.&lt;/p></description></item><item><title>How to Benchmark Java Code Using JUnit and JMH</title><link>https://www.nickolasfisher.com/blog/how-to-benchmark-java-code-using-junit-and-jmh/</link><pubDate>Sat, 10 Nov 2018 12:28:58 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-benchmark-java-code-using-junit-and-jmh/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/jmh-junit-intro">on GitHub&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://openjdk.java.net/projects/code-tools/jmh/">JMH&lt;/a> is a lightweight code generator that can benchmark Java code. While many of the performance bottlenecks in today&amp;rsquo;s world are related to network calls and/or database queries, it&amp;rsquo;s still a good idea to understand the performance of our code at a lower level. In particular, by automating performance tests on our code, we can usually at least ensure that the performance was not accidentally made worse by some refactoring effort.&lt;/p></description></item><item><title>Java IO: Creating and Traversing Files And Directories</title><link>https://www.nickolasfisher.com/blog/java-io-creating-and-traversing-files-and-directories/</link><pubDate>Sat, 03 Nov 2018 14:36:55 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/java-io-creating-and-traversing-files-and-directories/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/iodemos">on Github&lt;/a>&lt;/p>
&lt;p>Using the static methods in the &lt;code>Files&lt;/code> class, a member of the &lt;code>java.nio.file&lt;/code> package, we can manipulate the file system reasonably easily.&lt;/p></description></item><item><title>Java IO: Paths and Files</title><link>https://www.nickolasfisher.com/blog/java-io-paths-and-files/</link><pubDate>Sat, 03 Nov 2018 13:18:09 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/java-io-paths-and-files/</guid><description>&lt;p>The sample code for this repository can be found &lt;a href="https://github.com/nfisher23/iodemos">on Github&lt;/a>.&lt;/p>
&lt;p>System paths and file manipulation, usually within the java.nio package, in Java allow you to forgo some of the details related to streaming of files&amp;ndash;which, while they offer low level details and optimization opportunities, typically take longer to develop and get right.&lt;/p></description></item><item><title>Java IO: Zip Archive Manipulation</title><link>https://www.nickolasfisher.com/blog/java-io-zip-archive-manipulation/</link><pubDate>Sat, 03 Nov 2018 12:27:15 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/java-io-zip-archive-manipulation/</guid><description>&lt;p>The sample code associated with this post can be found &lt;a href="https://github.com/nfisher23/iodemos">on Github&lt;/a>.&lt;/p>
&lt;p>A &lt;a href="https://en.wikipedia.org/wiki/Zip_(file_format)">ZIP file format&lt;/a> is a compressed, lossless archive of files of files and/or directories. While the content being compressed will matter as to the algorithm&amp;rsquo;s effectiveness, it is a common way to transfer files among peers, particularly on many windows machines.&lt;/p></description></item><item><title>Java IO: Input Streaming</title><link>https://www.nickolasfisher.com/blog/java-io-input-streaming/</link><pubDate>Sat, 03 Nov 2018 12:00:01 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/java-io-input-streaming/</guid><description>&lt;p>The sample code associated with this post can be found &lt;a href="https://github.com/nfisher23/iodemos">on Github&lt;/a>.&lt;/p>
&lt;p>In Java, the input and output stream abstraction can be used with file systems or across networks. While a lot of these abstractions have been abstracted even further
away with modern libraries and tools (via servlets, for example), understanding the basics makes solving things like performance issues a little easier to wrap your head around.&lt;/p></description></item><item><title>The Everything Store, Jeff Bezos and the Age of Amazon: Summary In Quotes</title><link>https://www.nickolasfisher.com/blog/the-everything-store-jeff-bezos-and-the-age-of-amazon-summary-in-quotes/</link><pubDate>Sun, 28 Oct 2018 18:05:38 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-everything-store-jeff-bezos-and-the-age-of-amazon-summary-in-quotes/</guid><description>&lt;p>&lt;a href="https://www.amazon.com/Everything-Store-Jeff-Bezos-Amazon/dp/0316219282/ref=tmm_pap_swatch_0?_encoding=UTF8&amp;amp;qid=1541261148&amp;amp;sr=8-1-spons">The Everything Store&lt;/a>, by Brad Stone, is a critical and beginning-to-end (well, middle, since they still labor on) look at how Amazon came to be. Unlike many books about technology founders, Stone does not descend into &amp;ldquo;hero worship,&amp;rdquo; and instead tries to stick to cold, hard facts.&lt;/p></description></item><item><title>How to Provision a Linux Server With Any Version of Java via a Bash Script</title><link>https://www.nickolasfisher.com/blog/how-to-provision-a-linux-server-with-any-version-of-java-via-a-bash-script/</link><pubDate>Sun, 28 Oct 2018 14:29:38 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-provision-a-linux-server-with-any-version-of-java-via-a-bash-script/</guid><description>&lt;p>While we would all like to be up to date, sometimes legacy systems handcuff us into using an older version of software. Java is no exception, and in some cases we
have to resort to using, say, Java 8, instead of the latest version with all of the security updates that we need.&lt;/p></description></item><item><title>How to Simulate Distributed Systems in the Cloud with Vagrant</title><link>https://www.nickolasfisher.com/blog/how-to-simulate-distributed-systems-in-the-cloud-with-vagrant/</link><pubDate>Sun, 28 Oct 2018 14:28:13 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-simulate-distributed-systems-in-the-cloud-with-vagrant/</guid><description>&lt;p>In our last post on &lt;a href="https://nickolasfisher.com/blog/How-to-Set-Up-A-Private-Local-Network-On-Your-PC-With-VirtualBox">simulating a cloud environment on your local machine&lt;/a>,
we saw that we could use virtual box to create a virtual machine that could both talk to your local computer, with its own IP address, and to the internet.&lt;/p></description></item><item><title>How to Set Up A Private Local Network On Your PC With VirtualBox</title><link>https://www.nickolasfisher.com/blog/how-to-set-up-a-private-local-network-on-your-pc-with-virtualbox/</link><pubDate>Sun, 28 Oct 2018 14:27:31 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-set-up-a-private-local-network-on-your-pc-with-virtualbox/</guid><description>&lt;p>While you can always spin up a &lt;a href="https://www.digitalocean.com/">Digital Ocean&lt;/a> or &lt;a href="https://www.linode.com/">Linode&lt;/a> Virtual Private Server to toy around with,
that both costs money (pennies, at most a dollar or two, admittedly) and isn&amp;rsquo;t an extremely fast feedback loop for server provisioning. What we really want, as developers, is a way to test out an idea, see its feasibility, and preferably
tinker with that idea until it&amp;rsquo;s solid.&lt;/p></description></item><item><title>The New New Thing, A Silicon Valley Story: Summary in Quotes</title><link>https://www.nickolasfisher.com/blog/the-new-new-thing-a-silicon-valley-story-summary-in-quotes/</link><pubDate>Sat, 27 Oct 2018 15:58:30 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-new-new-thing-a-silicon-valley-story-summary-in-quotes/</guid><description>&lt;p>&lt;a href="https://www.amazon.com/New-Thing-Silicon-Valley-Story/dp/0393347818/ref=tmm_pap_swatch_0?_encoding=UTF8&amp;amp;qid=1541260718&amp;amp;sr=8-1">The New New Thing&lt;/a>, by Michael Lewis, is a pseudo biography of Jim Clark, meant to be introspective of the modern day tech industry. While it was written nearly twenty years ago, much of the culture that was unearthed in the 1990s still remains in Silicon Valley, and the attitude of a man who founded three separate billion dollar companies is something to pay very close attention to.&lt;/p></description></item><item><title>Never Split the Difference by Chris Voss: Summary In Quotes</title><link>https://www.nickolasfisher.com/blog/never-split-the-difference-by-chris-voss-summary-in-quotes/</link><pubDate>Sat, 27 Oct 2018 15:47:45 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/never-split-the-difference-by-chris-voss-summary-in-quotes/</guid><description>&lt;p>&lt;a href="https://www.amazon.com/Never-Split-Difference-Negotiating-Depended/dp/0062407805/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;amp;qid=1541260114&amp;amp;sr=8-2">Never Split the Difference&lt;/a>, by Chris Voss, is a book about how to negotiate. As opposed to theoreticians in a classroom, Chris Voss spent a great part of his life negotiating in the real world, and with the highest stakes imaginable, as an FBI hostage negotiator.&lt;/p></description></item><item><title>Skin In The Game by Nassim Nicholas Taleb: Summary In Quotes</title><link>https://www.nickolasfisher.com/blog/skin-in-the-game-by-nassim-nicholas-taleb-summary-in-quotes/</link><pubDate>Sat, 27 Oct 2018 15:34:27 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/skin-in-the-game-by-nassim-nicholas-taleb-summary-in-quotes/</guid><description>&lt;p>The topic of this summary in quotes is &lt;a href="https://www.amazon.com/Skin-Game-Hidden-Asymmetries-Daily/dp/042528462X">Skin In the Game&lt;/a>. The book&amp;rsquo;s central argument is that people who don&amp;rsquo;t participate in both the downside and upside of something don&amp;rsquo;t know what they are talking about. Simply put, if you haven&amp;rsquo;t been chastised for failure in the real world and promoted for excellence in that same real world, then you will fail to actually know how the real world works.&lt;/p></description></item><item><title>The Java Stream API: Parallel Streams</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-parallel-streams/</link><pubDate>Sun, 21 Oct 2018 20:03:56 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-parallel-streams/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>Parallel Streams are simple to generate in Java. Instead of calling .stream(), you simply call parallelStream(). Here, we&amp;rsquo;ll take our familiar list of names:&lt;/p></description></item><item><title>The Java Stream API: Primitive Streams</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-primitive-streams/</link><pubDate>Sun, 21 Oct 2018 19:49:49 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-primitive-streams/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>While Streams in Java would typically be used on POJO or POJO-like data structures, Java also lets us deal directly with primitive type streams.
Thanks to Java&amp;rsquo;s type erasure, something like Stream&lt;!-- raw HTML omitted --> would not work, as the type argument must be an Object.&lt;/p></description></item><item><title>The Java Stream API: Reduction Operations</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-reduction-operations/</link><pubDate>Sun, 21 Oct 2018 19:38:40 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-reduction-operations/</guid><description>&lt;p>The sample code for this post can be found &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>Reduction operations are a way to consolidate collections into one simple result.&lt;/p></description></item><item><title>The Java Stream API: Collecting Downstream Elements</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-collecting-downstream-elements/</link><pubDate>Sun, 21 Oct 2018 16:29:32 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-collecting-downstream-elements/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>One interesting feature of collecting streams using the &lt;code>Collectors.groupingBy(..)&lt;/code> method is the ability to manipulate &lt;em>downstream&lt;/em> elements. Basically,
this means that, after you group the keys of the map, you can further make changes to the collection that the map is pointing to. By default, it collects to a list.&lt;/p></description></item><item><title>The Java Stream API: Collecting Into Maps</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-collecting-into-maps/</link><pubDate>Sun, 21 Oct 2018 16:07:06 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-collecting-into-maps/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>Taking a stream of POJOs and transforming it into a map is one of the more common uses of Streams.
There are a few built in ways to get what you want. The simplest way to map one field to another in a POJO is by
using the &lt;code>.toMap(..)&lt;/code> method.&lt;/p></description></item><item><title>The Java Stream API: An Introduction to Collecting Results</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-an-introduction-to-collecting-results/</link><pubDate>Sun, 21 Oct 2018 15:46:38 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-an-introduction-to-collecting-results/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>Calling &lt;code>collect(..)&lt;/code> on a stream terminates a stream into a collection. We&amp;rsquo;ve already seen that calling collect(Collectors.toList()) moves your stream into
a List&lt;!-- raw HTML omitted -->, but you can also collect into a set. If we take our familiar collection of names in a String collection:&lt;/p></description></item><item><title>The Java Stream API: Creating Optional Types</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-creating-optional-types/</link><pubDate>Sun, 21 Oct 2018 15:22:54 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-creating-optional-types/</guid><description>&lt;p>You can view the sample code associated with this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>While Optionals are often used in conjunction with the Java Stream API, you can also create your own.
Now, why would you want to do that? Simply put, null pointer exceptions are not a fun time, and embracing optional
types will greatly simplify code development, and prevent premature graying hair.&lt;/p></description></item><item><title>The Java Stream API: How to Work With Optional Types</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-how-to-work-with-optional-types/</link><pubDate>Sat, 20 Oct 2018 21:59:38 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-how-to-work-with-optional-types/</guid><description>&lt;p>You can find the sample code associated with this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>If Java programmers had a generic Facebook page, they would collectively have an &amp;ldquo;it&amp;rsquo;s complicated&amp;rdquo; relationship with the null value.&lt;/p></description></item><item><title>The Java Stream API: Concatenating, Sorting, and Flat-Mapping</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-concatenating-sorting-and-flatmapping/</link><pubDate>Sat, 20 Oct 2018 21:32:57 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-concatenating-sorting-and-flatmapping/</guid><description>&lt;p>The sample code associated with this post can be found &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>Sometimes, we will have two different streams of data that we want to aggregate into one stream to analyze. In that case, we can use the &lt;code>Stream.concat(..)&lt;/code> method. Here, if we take our list of names from before:&lt;/p></description></item><item><title>The Java Stream API: Generating Fibonacci Numbers</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-generating-fibonacci-numbers/</link><pubDate>Sat, 20 Oct 2018 21:13:49 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-generating-fibonacci-numbers/</guid><description>&lt;p>You can find the sample code for this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>From the knowledge gained via &lt;a href="https://nickolasfisher.com/blog/The-Java-Stream-API-Creating-Custom-Lazy-Infinite-Streams">creating custom Java Stream objects&lt;/a>, we can start
to have a little bit of fun with this. The fibonacci number sequence starts with [0, 1], and adds each of the previous two elements to create the next element in the sequence.
This looks like [0, 1, 1, 2, 3, 5, 8, 13, 21&amp;hellip;], and goes on &amp;ldquo;forever.&amp;rdquo; We can thus create a template that computes all Fibonacci numbers by implementing a Supplier&lt;!-- raw HTML omitted -->. like so:&lt;/p></description></item><item><title>The Java Stream API: Creating Custom, Lazy, Infinite Streams</title><link>https://www.nickolasfisher.com/blog/the-java-stream-api-creating-custom-lazy-infinite-streams/</link><pubDate>Sat, 20 Oct 2018 13:50:54 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-api-creating-custom-lazy-infinite-streams/</guid><description>&lt;p>You can find the sample code from this post &lt;a href="https://github.com/nfisher23/java_stream_api_samples">on GitHub&lt;/a>.&lt;/p>
&lt;p>There are a few built in ways to create your own custom streams. While many collections offer a direct &lt;code>.stream()&lt;/code> method,
you can also use &lt;code>Stream.of(..)&lt;/code> to just make one in place:&lt;/p></description></item><item><title>The Java Stream API--Introduction: Filter, Map, and Count</title><link>https://www.nickolasfisher.com/blog/the-java-stream-apiintroduction-filter-map-and-count/</link><pubDate>Sat, 20 Oct 2018 12:00:18 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/the-java-stream-apiintroduction-filter-map-and-count/</guid><description>&lt;p>The sample code provided with this series on the Java Stream API can be retrieved &lt;a href="https://github.com/nfisher23/java_stream_api_samples/tree/master">on GitHub&lt;/a>.&lt;/p></description></item><item><title>How to Set Up ClickOnce Continuous Deployment for WPF via Nginx</title><link>https://www.nickolasfisher.com/blog/how-to-set-up-clickonce-continuous-deployment-for-wpf-via-nginx/</link><pubDate>Wed, 08 Aug 2018 00:08:00 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-set-up-clickonce-continuous-deployment-for-wpf-via-nginx/</guid><description>&lt;p>I&amp;rsquo;ve been working on a small wpf project on GitHub that let&amp;rsquo;s you &lt;a href="https://github.com/nfisher23/SEPubViewer">view SEC filings on your desktop&lt;/a> in an intuitive way. Since EDGAR kind of sucks for a casual user, this is much more appealing.&lt;/p></description></item><item><title>How to Configure Visual Studio to Implement the Yarn Package Manager</title><link>https://www.nickolasfisher.com/blog/how-to-configure-visual-studio-to-implement-the-yarn-package-manager/</link><pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-configure-visual-studio-to-implement-the-yarn-package-manager/</guid><description>&lt;p>The old recommended way of getting packages like bootstrap and jquery easily into
a project was to use bower. That was convenient to add packages for projects where you were planning on providing
mostly server-side functionality, and could use bootstrap to handle page styling, for example.&lt;/p></description></item><item><title>How To Make a Basic Working Contact Form With ASP .NET Core MVC and MailKit</title><link>https://www.nickolasfisher.com/blog/how-to-make-a-basic-working-contact-form-with-asp-net-core-mvc-and-mailkit/</link><pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate><guid>https://www.nickolasfisher.com/blog/how-to-make-a-basic-working-contact-form-with-asp-net-core-mvc-and-mailkit/</guid><description>&lt;p>Modern day website owners prefer not to leave their email address open and exploitable on the internet.
Enter the Contact page, which will usually have some basic fields for the visitor of the site to fill out like
Name, Email Address, Phone, and Message to send to someone who can help them out.&lt;/p></description></item></channel></rss>