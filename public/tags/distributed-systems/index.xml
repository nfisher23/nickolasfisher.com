<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Distributed Systems on Nick Fisher&#39;s tech blog</title>
    <link>http://localhost:1313/tags/distributed-systems/</link>
    <description>Recent content in Distributed Systems on Nick Fisher&#39;s tech blog</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <copyright>2018-{year}</copyright>
    <lastBuildDate>Sat, 01 May 2021 14:44:31 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/distributed-systems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using Redis as a Distributed Lock with Lettuce</title>
      <link>http://localhost:1313/blog/using-redis-as-a-distributed-lock-with-lettuce/</link>
      <pubDate>Sat, 01 May 2021 14:44:31 +0000</pubDate>
      <guid>http://localhost:1313/blog/using-redis-as-a-distributed-lock-with-lettuce/</guid>
      <description>&lt;p&gt;The source code for this article &lt;a href=&#34;https://github.com/nfisher23/reactive-programming-webflux&#34;&gt;can be found on Github&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Using Redis as a best effort locking mechanism can be very useful in practice, to prevent two logical threads from clobbering each other. While redis locking is certainly not perfect, and &lt;a href=&#34;https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html&#34;&gt;you shouldn&#39;t use redis locking if the underlying operation can&#39;t be occasionally done twice&lt;/a&gt;, it can still be useful for that &amp;quot;best effort, do this once&amp;quot; use case.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pre Loading Lua Scripts into Clustered Redis with Lettuce</title>
      <link>http://localhost:1313/blog/pre-loading-lua-scripts-into-clustered-redis-with-lettuce/</link>
      <pubDate>Sun, 25 Apr 2021 17:37:07 +0000</pubDate>
      <guid>http://localhost:1313/blog/pre-loading-lua-scripts-into-clustered-redis-with-lettuce/</guid>
      <description>&lt;p&gt;The source code for what follows &lt;a href=&#34;https://github.com/nfisher23/reactive-programming-webflux&#34;&gt;can be found on github&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In a previous article, we showed how to &lt;a href=&#34;https://nickolasfisher.com/blog/Pre-Loading-a-Lua-Script-into-Redis-With-Lettuce&#34;&gt;efficiently execute a lua script in redis using lettuce&lt;/a&gt;. To really scale our caching solution horizontally [and elegantly deal with many scaling headaches], we will also want to make sure we can execute our lua scripts against clustered redis, which as we&#39;ll see here is pretty straightforward.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Working with Lists in Redis using Lettuce and Webflux</title>
      <link>http://localhost:1313/blog/working-with-lists-in-redis-using-lettuce-and-webflux/</link>
      <pubDate>Sun, 11 Apr 2021 21:14:08 +0000</pubDate>
      <guid>http://localhost:1313/blog/working-with-lists-in-redis-using-lettuce-and-webflux/</guid>
      <description>&lt;p&gt;As of this writing, there are a solid &lt;a href=&#34;https://redis.io/commands/#list&#34;&gt;twenty or so commands you can execute against redis for the list data type&lt;/a&gt;. This article will be walking through some of the more common operations you are likely to need when interacting with redis and lists using lettuce, and &lt;a href=&#34;https://github.com/nfisher23/reactive-programming-webflux&#34;&gt;the source code can be found on Github&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Hashtags in Clustered Redis with Lettuce and Webflux</title>
      <link>http://localhost:1313/blog/using-hashtags-in-clustered-redis-with-lettuce-and-webflux/</link>
      <pubDate>Sun, 11 Apr 2021 16:12:09 +0000</pubDate>
      <guid>http://localhost:1313/blog/using-hashtags-in-clustered-redis-with-lettuce-and-webflux/</guid>
      <description>&lt;p&gt;In clustered redis, any non hash tagged key can be sent unpredictably [well, actually predictably, if you know the formula] to any given primary node in the cluster. The very basic way it works is:&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to use Embedded Redis to Test a Lettuce Client in Spring Boot Webflux</title>
      <link>http://localhost:1313/blog/how-to-use-embedded-redis-to-test-a-lettuce-client-in-spring-boot-webflux/</link>
      <pubDate>Sat, 27 Mar 2021 21:22:32 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-use-embedded-redis-to-test-a-lettuce-client-in-spring-boot-webflux/</guid>
      <description>&lt;p&gt;The source code for this article &lt;a href=&#34;https://github.com/nfisher23/reactive-programming-webflux/tree/master/reactive-redis&#34;&gt;can be found on Github&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lettuce-io/lettuce-core&#34;&gt;Lettuce&lt;/a&gt; is a redis client with reactive support. There is a super handy &lt;a href=&#34;https://github.com/kstyrc/embedded-redis&#34;&gt;embedded redis for java project&lt;/a&gt; out there, and this kind of integration testing inside your service is worth its weight in gold, in my humble opinion. This post will detail how to merge both of these worlds together, and set up redis integration tests when you&#39;re using a lettuce client.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Working with Nested Attributes, DynamoDB, and the Java SDK 2.0</title>
      <link>http://localhost:1313/blog/working-with-nested-attributes-dynamodb-and-the-java-sdk-20/</link>
      <pubDate>Sun, 15 Nov 2020 22:59:11 +0000</pubDate>
      <guid>http://localhost:1313/blog/working-with-nested-attributes-dynamodb-and-the-java-sdk-20/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.Attributes.html&#34;&gt;Nested attributes in DynamoDB&lt;/a&gt; are a way to group data within an item together. The attributes are said to be nested if they are embedded within another attribute.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Query a DynamoDB Local Secondary Index with Java</title>
      <link>http://localhost:1313/blog/query-a-dynamodb-local-secondary-index-with-java/</link>
      <pubDate>Sat, 31 Oct 2020 22:49:54 +0000</pubDate>
      <guid>http://localhost:1313/blog/query-a-dynamodb-local-secondary-index-with-java/</guid>
      <description>&lt;p&gt;DynamoDB&#39;s Local Secondary Indexes allow for more query flexibility than a traditional partition and range key combination. They are also the only index in DynamoDB where a strongly consistent read can be requested [global secondary indexes, the other index that dynamo supports, can at best be eventually consistent]. I will walk through an example for how to use local secondary indexes in dynamo using the AWS SDK 2.0 for Java, which has full reactive support, in this post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Set Time to Live [TTL] on DynamoDB Items using Java</title>
      <link>http://localhost:1313/blog/set-time-to-live-ttl-on-dynamodb-items-using-java/</link>
      <pubDate>Sun, 18 Oct 2020 13:43:39 +0000</pubDate>
      <guid>http://localhost:1313/blog/set-time-to-live-ttl-on-dynamodb-items-using-java/</guid>
      <description>&lt;p&gt;In this post, we&#39;ll demonstrate how &lt;a href=&#34;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html&#34;&gt;expiring items in DynamoDB&lt;/a&gt; works in java, using the AWS SDK 2.0+, which has full reactive support.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Querying DynamoDB in Java with the AWS SDK 2.0</title>
      <link>http://localhost:1313/blog/querying-dynamodb-in-java-with-the-aws-sdk-20/</link>
      <pubDate>Sun, 18 Oct 2020 13:38:22 +0000</pubDate>
      <guid>http://localhost:1313/blog/querying-dynamodb-in-java-with-the-aws-sdk-20/</guid>
      <description>&lt;p&gt;Queries in DynamoDB allow you to find data. This is only an option to you if your table has a partition and sort key.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Setup SNS Message Forwarding to SQS with the AWS CLI</title>
      <link>http://localhost:1313/blog/how-to-setup-sns-message-forwarding-to-sqs-with-the-aws-cli/</link>
      <pubDate>Sat, 15 Aug 2020 20:42:47 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-setup-sns-message-forwarding-to-sqs-with-the-aws-cli/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/sns/latest/dg/welcome.html&#34;&gt;Amazon SNS&lt;/a&gt; is AWS&#39;s solution to pub/sub. In a large, distributed system, decoupling &lt;em&gt;events&lt;/em&gt; from services that &lt;em&gt;need to act on those events&lt;/em&gt; allows for teams that own different services to better work in parallel, and also prevents the need for coordinating code deploys to deliver new features. If a services is already publishing a generic event, other services can hook into that event and act on them without needing anything but a bit of infrastructure.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DynamoDB Streams and Python: A Working Introduction</title>
      <link>http://localhost:1313/blog/dynamodb-streams-and-python-a-working-introduction/</link>
      <pubDate>Sun, 26 Jul 2020 21:54:59 +0000</pubDate>
      <guid>http://localhost:1313/blog/dynamodb-streams-and-python-a-working-introduction/</guid>
      <description>&lt;p&gt;DynamoDB Streams is AWS&#39;s home grown &lt;a href=&#34;https://en.wikipedia.org/wiki/Change_data_capture&#34;&gt;Change Data Capture [CDC]&lt;/a&gt; mechanism, which allows the consumer of the stream to see records probably in approximately the order they were created [it&#39;s basically impossible, at scale, to guarantee that all records across all partitions will somehow stream the data in exactly the same order that it was written]. This is a pretty fantastic feature because it allows us to reliably do &lt;em&gt;&amp;mdash;something&amp;mdash;&lt;/em&gt; after we add new data, update existing data, or delete existing data. As long as all the stream records are read and processed, we can ensure at least once processing on data changes and then go sleep soundly at night knowing that there is one less edge case in our application. Combine that with the natural scale that DynamoDB provides via its leaderless architecture and you can build this thing once and probably never have to worry about it handling more load ever again.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DynamoDB Basics: A Hands On Tutorial</title>
      <link>http://localhost:1313/blog/dynamodb-basics-a-hands-on-tutorial/</link>
      <pubDate>Sun, 12 Jul 2020 18:36:05 +0000</pubDate>
      <guid>http://localhost:1313/blog/dynamodb-basics-a-hands-on-tutorial/</guid>
      <description>&lt;p&gt;DynamoDB is a fully managed distributed datastore that does a great job of alleviating the operational overhead of building very scalable systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How To Create a Digital Ocean Droplet and Provision It Using Ansible</title>
      <link>http://localhost:1313/blog/how-to-create-a-digital-ocean-droplet-and-provision-it-using-ansible/</link>
      <pubDate>Sat, 15 Jun 2019 20:40:48 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-create-a-digital-ocean-droplet-and-provision-it-using-ansible/</guid>
      <description>&lt;p&gt;Ansible allows you to provision servers in an idempotent fashion. It lets you see the state of your VM configuration as it resides in code, which is light years better than the sysadmin ways of yesterday.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Register a Spring Boot Service to a Consul Cluster</title>
      <link>http://localhost:1313/blog/how-to-register-a-spring-boot-service-to-a-consul-cluster/</link>
      <pubDate>Sat, 25 May 2019 16:24:46 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-register-a-spring-boot-service-to-a-consul-cluster/</guid>
      <description>&lt;p&gt;In a previous post, we saw &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Provision-a-Consul-ClientServer-Cluster-using-Ansible&#34;&gt;how to provision a simple consul client/server cluster using Ansible&lt;/a&gt;. We will now look at interacting with that cluster by showing how to register a spring boot application to it, using &lt;a href=&#34;https://cloud.spring.io/spring-cloud-consul/spring-cloud-consul.html&#34;&gt;spring cloud consul&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Provision a Consul Client-Server Cluster using Ansible</title>
      <link>http://localhost:1313/blog/how-to-provision-a-consul-clientserver-cluster-using-ansible/</link>
      <pubDate>Sat, 27 Apr 2019 21:15:18 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-provision-a-consul-clientserver-cluster-using-ansible/</guid>
      <description>&lt;p&gt;The source code for this blog post can be found &lt;a href=&#34;https://github.com/nfisher23/some-ansible-examples/tree/master/consul-server&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.consul.io&#34;&gt;Consul&lt;/a&gt; can run in either client or server mode. As far as Consul is concerned, the primary difference between client and server mode are that Consul Servers participate in the consensus quorum, store cluster state, and handle queries. Consul Agents are often deployed to act as middle-men between the services and the Consul Servers, which need to be highly available by design.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Migrate a Real PostgreSQL Database Using Flyway with Spring Boot</title>
      <link>http://localhost:1313/blog/how-to-migrate-a-real-postgresql-database-using-flyway-with-spring-boot/</link>
      <pubDate>Sat, 20 Apr 2019 16:37:18 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-migrate-a-real-postgresql-database-using-flyway-with-spring-boot/</guid>
      <description>&lt;p&gt;You can see the source code for this post &lt;a href=&#34;https://github.com/nfisher23/postgres-flyway-example&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;We spent the last post figuring out &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Migrate-An-Embedded-PostgreSQL-Database-Using-Flyway-in-Spring-Boot&#34;&gt;how to migrate an embedded PostgreSQL database using Spring&lt;/a&gt;, while trying to side-step the extra magic that comes along with the framework. Here, we are going to build on that work to migrate a real PostgreSQL instance, which we will build in a local Vagrant Virtual Machine.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to do a Rolling Upgrade of Multiple Logstash Instances Using Ansible</title>
      <link>http://localhost:1313/blog/how-to-do-a-rolling-upgrade-of-multiple-logstash-instances-using-ansible/</link>
      <pubDate>Sun, 17 Mar 2019 23:27:43 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-do-a-rolling-upgrade-of-multiple-logstash-instances-using-ansible/</guid>
      <description>&lt;p&gt;You can see the source code for this post &lt;a href=&#34;https://github.com/nfisher23/some-ansible-examples&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In a previous post on &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Provision-Multiple-Logstash-Hosts-Using-Ansible&#34;&gt;How to Provision Multiple Logstash Hosts Using Ansible&lt;/a&gt;, we saw that provisioning logstash is pretty straightforward. However, what do we do with it after it&#39;s been out there transforming messages this entire time? Given that elastic comes out with a new version of Logstash every fifteen or twenty minutes, a wise person would look to automate the upgrade process as soon as possible.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to do a Rolling Upgrade of an Elasticsearch Cluster Using Ansible</title>
      <link>http://localhost:1313/blog/how-to-do-a-rolling-upgrade-of-an-elasticsearch-cluster-using-ansible/</link>
      <pubDate>Sat, 16 Mar 2019 23:17:03 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-do-a-rolling-upgrade-of-an-elasticsearch-cluster-using-ansible/</guid>
      <description>&lt;p&gt;You can see the source code for this blog post &lt;a href=&#34;https://github.com/nfisher23/some-ansible-examples&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In a previous post, we saw &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Provision-a-Multi-Node-Elasticsearch-Cluster-Using-Ansible&#34;&gt;how to provision a multi-node elasticsearch cluster using ansible&lt;/a&gt;. The problem with that post is that, by the time I was done writing it, &lt;em&gt;Elastic had already come out with a new version of elasticsearch&lt;/em&gt;. I&#39;m being mildly facetious, but not really. They release new versions very quickly, even by the standards of modern software engineering.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Provision a Linux VM With Kibana Using Ansible</title>
      <link>http://localhost:1313/blog/how-to-provision-a-linux-vm-with-kibana-using-ansible/</link>
      <pubDate>Sat, 16 Mar 2019 15:37:40 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-provision-a-linux-vm-with-kibana-using-ansible/</guid>
      <description>&lt;p&gt;The corresponding source code for this post is available &lt;a href=&#34;https://github.com/nfisher23/some-ansible-examples&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/products/kibana&#34;&gt;Kibana&lt;/a&gt; is a fancy pants web application that tries to make data in Elasticsearch user-friendly. Rounding out the previous two posts on &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Provision-a-Multi-Node-Elasticsearch-Cluster-Using-Ansible&#34;&gt;how to install an elasticsearch cluster&lt;/a&gt; and &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Install-Multiple-Logstash-Hosts-Using-Ansible&#34;&gt;how to install multiple logstash hosts&lt;/a&gt;, I will now show you how to stack kibana on top of them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Provision Multiple Logstash Hosts Using Ansible</title>
      <link>http://localhost:1313/blog/how-to-provision-multiple-logstash-hosts-using-ansible/</link>
      <pubDate>Wed, 06 Mar 2019 23:33:35 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-provision-multiple-logstash-hosts-using-ansible/</guid>
      <description>&lt;p&gt;The source code for this post can be found &lt;a href=&#34;https://github.com/nfisher23/some-ansible-examples&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/products/logstash&#34;&gt;Logstash&lt;/a&gt; primarily exists to extract useful information out of plain-text logs. Most applications have custom logs which are in whatever format the person writing them thought would look reasonable&amp;hellip;usually to a human, and not to a machine. While countless future developer hours would be preserved if everything were just in JSON, that is sadly not even remotely the case, and in particular it&#39;s not the case for log files. Logstash aims to be the intermediary between the various log formats and Elasticsearch, which is the document database provided by Elastic as well.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Provision a Multi Node Elasticsearch Cluster Using Ansible</title>
      <link>http://localhost:1313/blog/how-to-provision-a-multi-node-elasticsearch-cluster-using-ansible/</link>
      <pubDate>Sun, 03 Mar 2019 23:15:27 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-provision-a-multi-node-elasticsearch-cluster-using-ansible/</guid>
      <description>&lt;p&gt;You can see the sample code for this tutorial &lt;a href=&#34;https://github.com/nfisher23/some-ansible-examples&#34;&gt;on GitHub.&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt; is a distributed, NoSQL, document database, built on top of Lucene. There are so many things I could say about Elasticsearch, but instead I&#39;ll focus on how to install a simple 3-node cluster with an Ansible role. The following example will not have any security baked into it, so it&#39;s really just a starting point to get you up and running.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Simple Zero Downtime Continuous Integration Pipeline for Spring MVC</title>
      <link>http://localhost:1313/blog/a-simple-zero-downtime-continuous-integration-pipeline-for-spring-mvc/</link>
      <pubDate>Sun, 25 Nov 2018 15:53:22 +0000</pubDate>
      <guid>http://localhost:1313/blog/a-simple-zero-downtime-continuous-integration-pipeline-for-spring-mvc/</guid>
      <description>&lt;p&gt;The sample code associated with what follows can be found &lt;a href=&#34;https://github.com/nfisher23/simple-cicd-pipeline-with-spring&#34;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;One of the biggest paradigm shifts in software engineering, since the invention of the computer and software that would run on it, was the idea of a MVR (minimum viable release) or MVP (minimum viable product). With the lack of internet access becoming the exception in developed countries, it becomes more and more powerful to put your product out there on display, and to design a way to continuously make improvements to it. In the most aggressive of circumstances, you want to be able to push something up to a source control server, then let an automated process perform the various steps required to actually deploy it in the real world. In the best case, you can achieve all of this with zero downtime&amp;ndash;basically, the users of your service are never inconvenienced by your decision to make a change. Setting up one very simple example of that is the subject of this post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A VagrantFile for Elasticsearch, Logstash, and Kibana (On Three Different Servers)</title>
      <link>http://localhost:1313/blog/a-vagrantfile-for-elasticsearch-logstash-and-kibana-on-three-different-servers/</link>
      <pubDate>Sun, 18 Nov 2018 13:42:46 +0000</pubDate>
      <guid>http://localhost:1313/blog/a-vagrantfile-for-elasticsearch-logstash-and-kibana-on-three-different-servers/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/&#34;&gt;Elasticsearch, Logstash, and Kibana&lt;/a&gt;, commonly referred to as ELK or the Elastic Stack, is a set of tools that can, well do a lot of things. It is most famous for its logging and analytics capabilities.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Provision a Linux Server With Any Version of Java via a Bash Script</title>
      <link>http://localhost:1313/blog/how-to-provision-a-linux-server-with-any-version-of-java-via-a-bash-script/</link>
      <pubDate>Sun, 28 Oct 2018 14:29:38 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-provision-a-linux-server-with-any-version-of-java-via-a-bash-script/</guid>
      <description>&lt;p&gt;While we would all like to be up to date, sometimes legacy systems handcuff us into using an older version of software. Java is no exception, and in some cases we&#xA;have to resort to using, say, Java 8, instead of the latest version with all of the security updates that we need.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Simulate Distributed Systems in the Cloud with Vagrant</title>
      <link>http://localhost:1313/blog/how-to-simulate-distributed-systems-in-the-cloud-with-vagrant/</link>
      <pubDate>Sun, 28 Oct 2018 14:28:13 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-simulate-distributed-systems-in-the-cloud-with-vagrant/</guid>
      <description>&lt;p&gt;In our last post on &lt;a href=&#34;https://nickolasfisher.com/blog/How-to-Set-Up-A-Private-Local-Network-On-Your-PC-With-VirtualBox&#34;&gt;simulating a cloud environment on your local machine&lt;/a&gt;,&#xA;we saw that we could use virtual box to create a virtual machine that could both talk to your local computer, with its own IP address, and to the internet.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Set Up A Private Local Network On Your PC With VirtualBox</title>
      <link>http://localhost:1313/blog/how-to-set-up-a-private-local-network-on-your-pc-with-virtualbox/</link>
      <pubDate>Sun, 28 Oct 2018 14:27:31 +0000</pubDate>
      <guid>http://localhost:1313/blog/how-to-set-up-a-private-local-network-on-your-pc-with-virtualbox/</guid>
      <description>&lt;p&gt;While you can always spin up a &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;Digital Ocean&lt;/a&gt; or &lt;a href=&#34;https://www.linode.com/&#34;&gt;Linode&lt;/a&gt; Virtual Private Server to toy around with,&#xA;that both costs money (pennies, at most a dollar or two, admittedly) and isn&#39;t an extremely fast feedback loop for server provisioning. What we really want, as developers, is a way to test out an idea, see its feasibility, and preferably&#xA;tinker with that idea until it&#39;s solid.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
